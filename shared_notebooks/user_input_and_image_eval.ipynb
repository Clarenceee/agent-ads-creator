{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1746365439762,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"},"user_tz":-480},"id":"voVpOarJfLWd","outputId":"32828b17-6d6c-4992-a86a-c59b4cc959d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nColab Notebook: AI Imagery Pipeline Test (Initial Stages)\\n\\nThis notebook simulates the initial stages of the AI Imagery Pipeline:\\n1. User Input Collection (Custom & Task-Specific Modes) with Social Media Platform\\n2. Simplified JSON Output Generation (including image metadata)\\n3. Enhanced JSON Parsing & Validation (Simulated Client/Server)\\n4. Image Analysis using VLM (Simulated/LLM with Pydantic/Instructor) - Step 5\\n5. Marketing Strategy Generation (Simulated/LLM with Pydantic/Instructor) - Step 6 (Staged Reasoning: List of Niches -> Goals, No Pools, Retries, Token Usage)\\n6. Includes setup instructions for OpenRouter LLM integration.\\n7. Processing triggered by running the final cell directly.\\n8. Halts processing if Image Evaluation API call fails.\\n9. Saves final JSON and input image (if applicable) with unique filenames.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Colab Notebook: AI Imagery Pipeline Test (Initial Stages)\n","\n","This notebook simulates the initial stages of the AI Imagery Pipeline:\n","1. User Input Collection (Custom & Task-Specific Modes) with Social Media Platform\n","2. Simplified JSON Output Generation (including image metadata)\n","3. Enhanced JSON Parsing & Validation (Simulated Client/Server)\n","4. Image Analysis using VLM (Simulated/LLM with Pydantic/Instructor) - Step 5\n","5. Marketing Strategy Generation (Simulated/LLM with Pydantic/Instructor) - Step 6 (Staged Reasoning: List of Niches -> Goals, No Pools, Retries, Token Usage)\n","6. Includes setup instructions for OpenRouter LLM integration.\n","7. Processing triggered by running the final cell directly.\n","8. Halts processing if Image Evaluation API call fails.\n","9. Saves final JSON and input image (if applicable) with unique filenames.\n","\"\"\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10903,"status":"ok","timestamp":1746365450660,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"},"user_tz":-480},"id":"pCujMm07fWrO","outputId":"bbf17cc6-198a-434c-9579-a61c70280ff2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/345.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m337.9/345.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install openai pydantic instructor python-dotenv tenacity Pillow -q"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11519,"status":"ok","timestamp":1746365462203,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"},"user_tz":-480},"id":"vZBa7nH4fiBd","outputId":"30dc59dd-814e-4d74-c339-3b92e8c27158"},"outputs":[{"output_type":"stream","name":"stdout","text":["Libraries imported, Task Types, and Platforms defined.\n","Ensure 'openai' (>=1.0.0), 'pydantic', 'instructor', and 'tenacity' libraries are installed.\n"]}],"source":["# @title Setup: Import Libraries and Define Tasks/Platforms/Pools\n","import ipywidgets as widgets\n","from IPython.display import display, clear_output\n","import json\n","from PIL import Image\n","import io\n","import os\n","# Used for OpenRouter integration\n","# !pip install openai # Uncomment and run this line if openai library is not installed\n","from google.colab import drive\n","from dotenv import load_dotenv\n","import traceback\n","import base64 # For potential image encoding\n","from typing import List, Optional, Dict, Any # For Pydantic models\n","import random # For fallback simulation diversity\n","import time # For adding timestamps to logs\n","import pathlib # For handling paths and extensions\n","import datetime # For timestamped filenames\n","\n","try:\n","    # Use the new client-based import structure\n","    from openai import OpenAI, APIConnectionError, RateLimitError, APIStatusError\n","    from pydantic import BaseModel, Field, field_validator # Import Pydantic\n","    import instructor # Import instructor\n","    from tenacity import RetryError # Import RetryError for specific checking\n","except ImportError:\n","    print(\"Required libraries (openai>=1.0.0, pydantic, instructor, tenacity) not found.\")\n","    print(\"Please install them (`pip install -U openai pydantic instructor tenacity`) to use OpenRouter and Pydantic.\")\n","    OpenAI = None\n","    BaseModel = None # Set to None if import fails\n","    instructor = None\n","    RetryError = None # Set to None if import fails\n","    openai = None # Keep compatibility with older checks if needed, but prioritize OpenAI class\n","\n","\n","# Define the available task types for Task-Specific Mode\n","TASK_TYPES = [\n","    'Select Task...',\n","    '1. Product Photography',\n","    '2. Promotional Graphics & Announcements',\n","    '3. Store Atmosphere & Decor',\n","    '4. Menu Spotlights',\n","    '5. Cultural & Community Content',\n","    '6. Recipes & Food Tips',\n","    '7. Brand Story & Milestones',\n","    '8. Behind the Scenes Imagery'\n","]\n","\n","# Define target social media platforms with resolutions (Mandatory)\n","# Using a dictionary: Key = Display Name, Value = Resolution Dict\n","SOCIAL_MEDIA_PLATFORMS = {\n","    'Select Platform...': None, # Default Placeholder\n","    'Instagram Post (1:1 Square)': {'width': 1080, 'height': 1080, 'aspect_ratio': '1:1'},\n","    'Instagram Story/Reel (9:16 Vertical)': {'width': 1080, 'height': 1920, 'aspect_ratio': '9:16'},\n","    'Facebook Post (Mixed)': {'width': 1200, 'height': 630, 'aspect_ratio': '1.91:1 or 1:1'}, # FB is flexible, common link preview size\n","    'Pinterest Pin (2:3 Vertical)': {'width': 1000, 'height': 1500, 'aspect_ratio': '2:3'},\n","    'Xiaohongshu (Red Note) (3:4 Vertical)': {'width': 1080, 'height': 1440, 'aspect_ratio': '3:4'},\n","    # Add other relevant platforms if needed\n","}\n","# Get the list of display names for the dropdown widget\n","PLATFORM_DISPLAY_NAMES = list(SOCIAL_MEDIA_PLATFORMS.keys())\n","\n","\n","# --- Option Pools REMOVED (Mostly) ---\n","# Pools might still be used for fallback simulation or inspiration in prompts\n","TASK_GROUP_POOLS = {\n","    \"product_focus\": {\n","        \"audience\": [\"Foodies/Bloggers\", \"Local Residents\", \"Health-Conscious Eaters\", \"Budget-Conscious Diners\", \"Young Professionals (25-35)\"],\n","        \"niche\": [\"Casual Dining\", \"Fine Dining\", \"Cafe/Coffee Shop\", \"Ethnic Cuisine\", \"Takeaway/Delivery Focused\"],\n","        \"objective\": [\"Create Appetite Appeal\", \"Showcase Quality/Freshness\", \"Promote Specific Menu Item\", \"Increase Online Orders/Reservations\"],\n","        \"voice\": [\"Mouth-watering & Descriptive\", \"Sophisticated & Elegant\", \"Fresh & Vibrant\", \"Authentic & Honest\"]\n","    },\n","    \"default\": { # Fallback pool\n","        \"audience\": [\"Local Residents\", \"Young Professionals (25-35)\", \"Families with Children\", \"Foodies/Bloggers\"],\n","        \"niche\": [\"Casual Dining\", \"Cafe/Coffee Shop\", \"Takeaway/Delivery Focused\"],\n","        \"objective\": [\"Increase Brand Awareness\", \"Drive Foot Traffic\", \"Increase Engagement on Social Media\"],\n","        \"voice\": [\"Friendly & Casual\", \"Warm & Welcoming\", \"Authentic & Honest\"]\n","    }\n","}\n","# Helper function to get the appropriate pool based on task type string\n","def get_pools_for_task(task_type_str):\n","    if not task_type_str: return TASK_GROUP_POOLS[\"default\"]\n","    if task_type_str.startswith('1.') or task_type_str.startswith('4.'): return TASK_GROUP_POOLS[\"product_focus\"]\n","    # Add mappings for other task groups if defined\n","    return TASK_GROUP_POOLS[\"default\"] # Fallback\n","\n","\n","print(\"Libraries imported, Task Types, and Platforms defined.\")\n","if OpenAI and BaseModel and instructor and RetryError:\n","    print(\"Ensure 'openai' (>=1.0.0), 'pydantic', 'instructor', and 'tenacity' libraries are installed.\")\n","else:\n","    print(\"WARNING: One or more required libraries (openai, pydantic, instructor, tenacity) not imported. LLM/Pydantic features will be skipped.\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["034b7790a56746b7862a1072c523f442","4d3111f9ab494b85892f7057797d7142","6daf70531edd4b25bb689f83c86caef7"]},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1746365462245,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"},"user_tz":-480},"id":"SlIR0x1UfrW6","outputId":"87e0f8e5-5cbc-4ed2-8725-0c0f59a8fa2e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["RadioButtons(description='Select Mode:', options=('Custom Mode', 'Task-Specific Mode'), value='Custom Mode')"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"034b7790a56746b7862a1072c523f442"}},"metadata":{}}],"source":["# @title Step 1: Mode Selection\n","mode_selection = widgets.RadioButtons(\n","    options=['Custom Mode', 'Task-Specific Mode'],\n","    description='Select Mode:',\n","    disabled=False\n",")\n","\n","display(mode_selection)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318,"referenced_widgets":["0872cd666ab149578bd18267820d1dcd","62e4a8790b0440f2b4961095be59d3be","2541d82c8c064b6d804925da97cce2a1","bee1a206f4a7488f85cb0f25eba7fea1","973c2c7bc34a41a2a6289fe2e16dcaa3","8e5f7f65b9894c719a423807cd9b41b4","127e21a762bc4432a05c94b7fa8c63d3","4616e58cf6654595b4e63a189e2b2f45","6e85b5f2e5da41c492a5dbfac576ae05","5362e248c9b84fd980c1b4695b4c1543","3928405d15584354933b35f478068909","e5978779b80a41868886f56ed1af4f20","804bf02898ad441f94cfb065466fe6ce","c181a82dffb54b1e8f79ee8f3ba9a7b6","a90a796f014a4d2ea744772e14447b28","f1de97be7ee44c35998d61abd8a3757f","200b485ed0ad40bba72a1f89fc262497","3c723712a2bc4fed9dcebb4aa31e2922","218adfe7412d4cfb835b7da0b0ec0a94"]},"executionInfo":{"elapsed":458,"status":"ok","timestamp":1746365462708,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"},"user_tz":-480},"id":"t_RGw5wtf-hL","outputId":"52a4a4ae-4608-4747-f4ee-0df855f9a5fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input widgets configured. Select a mode above to see the relevant inputs.\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(VBox(children=(HTML(value='<h3>Custom Mode Inputs:</h3>'), Dropdown(description='*Platform Targ…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0872cd666ab149578bd18267820d1dcd"}},"metadata":{}}],"source":["# @title Step 2: Input Widgets Setup\n","# --- Common Widgets ---\n","platform_selection = widgets.Dropdown(\n","    options=PLATFORM_DISPLAY_NAMES, # Use display names for options\n","    value=PLATFORM_DISPLAY_NAMES[0], # Default to placeholder\n","    description='*Platform Target:', # Added asterisk for mandatory\n","    disabled=False,\n","    style={'description_width': 'initial'} # Adjust width if needed\n",")\n","\n","prompt_input = widgets.Textarea(\n","    value='',\n","    placeholder='Enter your text prompt here (describe style, composition, setting, etc.)...',\n","    description='Prompt:',\n","    layout={'height': '100px', 'width': '95%'}\n",")\n","\n","image_upload = widgets.FileUpload(\n","    accept='image/*',  # Accept image files\n","    multiple=False,   # Allow only single file upload\n","    description='Upload Image Ref:'\n",")\n","\n","image_instruction = widgets.Textarea(\n","    value='',\n","    placeholder='(Optional) Provide brief instructions for the uploaded image (e.g., \"Use the burger as the main subject\", \"Describe the style and setting\", \"Extract the text\"). If empty, only the main subject will be identified.',\n","    description='Image Instruction:',\n","    layout={'height': '60px', 'width': '95%'}\n",")\n","\n","# --- Task-Specific Widgets ---\n","task_selection = widgets.Dropdown(\n","    options=TASK_TYPES,\n","    value=TASK_TYPES[0], # Default to placeholder\n","    description='*Task Type:', # Added asterisk for mandatory\n","    disabled=False,\n","    style={'description_width': 'initial'}\n",")\n","\n","branding_elements_input = widgets.Textarea(\n","    value='',\n","    placeholder='(Optional) Describe branding elements (e.g., \"Use warm colors like #F5A623\", \"Include logo placeholder top-right\", \"Font: Playful Sans-serif\")...',\n","    description='Branding:',\n","    layout={'height': '80px', 'width': '95%'}\n",")\n","\n","task_description_input = widgets.Textarea(\n","    value='',\n","    placeholder='(Optional) Enter content specific to the task (e.g., \"Promo Text: 2-for-1 Coffee!\", \"Menu Item: Signature Pasta\", \"Milestone: 5 Year Anniversary\")...',\n","    description='Task Content:',\n","    layout={'height': '80px', 'width': '95%'}\n",")\n","\n","marketing_audience = widgets.Text(value='', placeholder='(Optional) e.g., Young professionals, families', description='Target Audience:')\n","marketing_objective = widgets.Text(value='', placeholder='(Optional) e.g., Increase engagement, drive sales', description='Objective:')\n","marketing_voice = widgets.Text(value='', placeholder='(Optional) e.g., Playful, sophisticated, casual', description='Voice:')\n","marketing_niche = widgets.Text(value='', placeholder='(Optional) e.g., Vegan cafe, fine dining', description='Niche:')\n","\n","marketing_goals_box = widgets.VBox([\n","    widgets.HTML(\"<b>Optional Marketing Goals:</b>\"),\n","    marketing_audience,\n","    marketing_objective,\n","    marketing_voice,\n","    marketing_niche\n","])\n","\n","# --- Layout Containers ---\n","# Note: platform_selection is added to both VBox containers\n","custom_mode_widgets = widgets.VBox([\n","    widgets.HTML(\"<h3>Custom Mode Inputs:</h3>\"),\n","    platform_selection, # Added Platform Selection\n","    prompt_input,\n","    image_upload,\n","    image_instruction\n","])\n","\n","task_specific_mode_widgets = widgets.VBox([\n","    widgets.HTML(\"<h3>Task-Specific Mode Inputs:</h3>\"),\n","    platform_selection, # Added Platform Selection\n","    task_selection,     # Task selection is mandatory for this mode\n","    prompt_input, # Re-use prompt input\n","    image_upload, # Re-use image upload\n","    image_instruction, # Re-use image instruction\n","    branding_elements_input,\n","    task_description_input,\n","    marketing_goals_box\n","])\n","\n","# --- Output Widget ---\n","output_area = widgets.Output()\n","\n","# --- Display Logic ---\n","input_container = widgets.VBox([]) # Empty container to hold dynamic widgets\n","\n","def on_mode_change(change):\n","    \"\"\"Handles switching between Custom and Task-Specific modes.\"\"\"\n","    # No need to clear output here as it's displayed separately later\n","    # with output_area:\n","    #    clear_output()\n","    if change['new'] == 'Custom Mode':\n","        input_container.children = [custom_mode_widgets]\n","    elif change['new'] == 'Task-Specific Mode':\n","        input_container.children = [task_specific_mode_widgets]\n","    else:\n","        input_container.children = []\n","\n","# Initialize display based on default mode\n","on_mode_change({'new': mode_selection.value})\n","\n","# Observe changes in mode selection\n","mode_selection.observe(on_mode_change, names='value')\n","\n","print(\"Input widgets configured. Select a mode above to see the relevant inputs.\")\n","# Display ONLY the input container here\n","display(input_container)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpIITq_pi4-h","executionInfo":{"status":"ok","timestamp":1746365490218,"user_tz":-480,"elapsed":2991,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"}},"outputId":"f3c91f2b-6b2f-4a21-f046-d91c53c40b6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","✅ Google Drive mounted successfully.\n","✅ Input file path set to: /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Google Drive mounted successfully.\n","✅ Input file path set to: /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook\n"]}],"source":["# @title Mount Google Drive and Set Input File Path\n","# This cell mounts your Google Drive to access files stored there.\n","# It will prompt you for authorization the first time you run it.\n","\n","try:\n","    drive.mount('/content/drive')\n","    print(\"✅ Google Drive mounted successfully.\")\n","\n","    # --- Define Input File Path on Google Drive ---\n","    # ** IMPORTANT: Update the filename if needed **\n","    DRIVE_BASE_PATH = '/content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook'\n","\n","    # Check if the directory and file exist after mounting\n","    if not os.path.isdir(DRIVE_BASE_PATH):\n","        print(f\"❌ Error: Google Drive directory not found: {DRIVE_BASE_PATH}\")\n","        print(\"   Please ensure the path is correct and Drive is mounted properly.\")\n","    else:\n","        print(f\"✅ Input file path set to: {DRIVE_BASE_PATH}\")\n","\n","except Exception as e:\n","    print(f\"❌ An error occurred during Google Drive mounting or path setting: {e}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2618,"status":"ok","timestamp":1746365486634,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"},"user_tz":-480},"id":"PZG_KYmchw9y","outputId":"8e9f4587-7073-44c8-d423-a2a0eb17e708"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded .env file from path: /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/colab_secrets/.env\n","OpenAI client configured for OpenRouter and patched with Instructor (max_retries=1).\n"]}],"source":["# @title Step 3: LLM Setup (OpenRouter - Optional but Recommended for Real Implementation)\n","\n","# --- Instructions ---\n","# 1. Get an API Key: Sign up at https://openrouter.ai to get your free API key.\n","# 2. Secure Your Key: In Colab, it's best practice to store secrets securely.\n","#    Go to the \"Secrets\" tab (key icon on the left panel) and add a new secret named 'OPENROUTER_API_KEY'\n","#    with your actual API key as the value. Enable \"Notebook access\".\n","# 3. Run this cell: It will attempt to load the key and configure the OpenAI client.\n","\n","# --- Configuration Code ---\n","# --- IMPORTANT ---\n","# Set your OpenRouter API key (using .env file or environment variable recommended)\n","dotenv_path = \"/content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/colab_secrets/.env\"\n","\n","if os.path.exists(dotenv_path):\n","    load_dotenv(dotenv_path=dotenv_path)\n","    print(f\"Loaded .env file from path: {dotenv_path}\")\n","else:\n","    print(f\"Error: .env file not found at path: {dotenv_path}\")\n","\n","OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n","GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY_3\")\n","\n","\n","# Select LLM service provider\n","LLM_SERVICE_PROVIDER = \"OpenRouter\" # or \"Gemini\" or \"openai\" or \"OpenRouter\"\n","IMG_EVAL_MODEL = \"openai/gpt-4.1-mini\" # Make sure this model supports image input via API gemini-2.5-pro-exp-03-25 openai/gpt-4.1-mini google/gemini-2.5-flash-preview\n","STRATEGY_MODEL = \"openai/gpt-4.1-mini\" # Keep mini for testing, but note limitations gemini-2.5-pro-exp-03-25 openai/gpt-4.1-mini google/gemini-2.5-flash-preview\n","\n","client = None\n","instructor_client = None # Initialize instructor client\n","MAX_LLM_RETRIES = 1 # Define max retries for LLM calls\n","\n","if OpenAI and instructor: # Check if both libraries are available\n","  if OPENROUTER_API_KEY or GEMINI_API_KEY:\n","    if LLM_SERVICE_PROVIDER == \"OpenRouter\":\n","      BASE_API_URL = \"https://openrouter.ai/api/v1\"\n","      BASE_API_KEY = OPENROUTER_API_KEY\n","    elif LLM_SERVICE_PROVIDER == \"Gemini\":\n","      BASE_API_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n","      BASE_API_KEY = GEMINI_API_KEY\n","\n","    try:\n","              # Initialize the base OpenAI client\n","              base_client = OpenAI(\n","                  api_key=BASE_API_KEY,\n","                  base_url=BASE_API_URL,\n","                  max_retries=MAX_LLM_RETRIES, # Configure retries here\n","                  # Pass headers during initialization if needed by OpenRouter or specific models\n","                  # default_headers={\n","                  #    \"HTTP-Referer\": \"http://localhost:8888\", # Replace with your app URL/Identifier\n","                  #    \"X-Title\": \"Colab Pipeline Tester\" # Replace with your app name/Identifier\n","                  # }\n","              )\n","              # Patch the client with instructor (NO max_retries argument here)\n","              instructor_client = instructor.patch(base_client)\n","              print(f\"OpenAI client configured for OpenRouter and patched with Instructor (max_retries={MAX_LLM_RETRIES}).\")\n","    except Exception as e:\n","              print(f\"Error initializing OpenAI client or patching with Instructor: {e}\")\n","              client = None # Ensure client is None if initialization fails\n","              instructor_client = None\n","  elif not OPENROUTER_API_KEY:\n","      print(\"⚠️ OpenRouter API Key not found.\")\n","      # OPENROUTER_API_KEY = input(\"Enter your OpenRouter API Key: \")\n","  elif not GEMINI_API_KEY:\n","      print(\"⚠️ Gemini API Key not found.\")\n","      # GEMINI_API_KEY = input(\"Enter your Gemini API Key: \")\n","  else:\n","      print(\"OpenAI client not configured for OpenRouter (API Key missing).\")\n","      print(\"LLM-dependent steps will use simulated data only.\")\n","else:\n","    print(\"OpenAI library (>=1.0.0) and/or Instructor library not available. Cannot configure OpenRouter.\")\n","    client = None # Ensure client is None if library is missing\n","    instructor_client = None"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"r7fLP59i0anj","executionInfo":{"status":"ok","timestamp":1746365486748,"user_tz":-480,"elapsed":113,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"}}},"outputs":[],"source":["# @title Step 4: Define Processing Functions\n","\n","# --- Processing Functions ---\n","\n","def validate_inputs(mode, inputs):\n","    \"\"\"\n","    Performs basic validation on the raw inputs (Simulates Client-Side).\n","    Checks mandatory fields before attempting to generate JSON.\n","    \"\"\"\n","    # --- MANDATORY CHECK: Social Media Platform ---\n","    # Check if the selected platform is the placeholder/default value\n","    if not inputs.get('platform') or inputs['platform'] == PLATFORM_DISPLAY_NAMES[0]:\n","        return False, \"Client-Side Validation Error: A target Social Media Platform must be selected.\"\n","\n","    if mode == 'Custom Mode':\n","        # Check if at least one of prompt or image is provided\n","        if not inputs.get('prompt') and not inputs.get('image_details'):\n","            return False, \"Client-Side Validation Error: Custom Mode requires either a text prompt or an uploaded image.\"\n","    elif mode == 'Task-Specific Mode':\n","        # --- MANDATORY CHECK: Task Type ---\n","        # Check if a valid task type is selected (not the placeholder)\n","        if not inputs.get('task_type') or inputs['task_type'] == TASK_TYPES[0]:\n","             return False, \"Client-Side Validation Error: Task-Specific Mode requires selecting a valid Task Type.\"\n","        # Add more task-specific mandatory checks here if needed (e.g., promo text for task 2)\n","        # Example: Check for task_content if task is Promotional Graphics\n","        # if inputs.get('task_type') == '2. Promotional Graphics & Announcements' and not inputs.get('task_content'):\n","        #     return False, \"Client-Side Validation Error: Promotional Graphics task requires Task Content (Promo Text).\"\n","\n","    # Check if image details exist if image was supposedly uploaded\n","    if inputs.get('image_widget_has_value') and not inputs.get('image_details'):\n","         # This indicates an internal error during image detail extraction\n","         return False, \"Client-Side Validation Error: Image was uploaded but details could not be extracted.\"\n","\n","    return True, \"Client-Side Validation: Inputs seem valid for the selected mode.\"\n","\n","def generate_initial_json(mode, inputs):\n","    \"\"\"Creates the structured JSON output based on validated inputs.\"\"\"\n","    image_ref_data = None\n","    if inputs.get('image_details'):\n","        image_ref_data = {\n","            \"filename\": inputs['image_details'].get('filename'),\n","            \"content_type\": inputs['image_details'].get('content_type'),\n","            \"size_bytes\": inputs['image_details'].get('size_bytes'),\n","            \"instruction\": inputs.get('image_instruction', None), # Instruction is separate from details\n","            # Store image content if needed for VLM call later\n","            \"image_content_base64\": inputs.get('image_content_base64', None)\n","        }\n","\n","    # Capture marketing goals even if partially filled or None/empty string\n","    marketing_goals_data = {\n","        \"target_audience\": inputs.get('mkt_audience') if inputs.get('mkt_audience') else None,\n","        \"objective\": inputs.get('mkt_objective') if inputs.get('mkt_objective') else None,\n","        \"voice\": inputs.get('mkt_voice') if inputs.get('mkt_voice') else None,\n","        \"niche\": inputs.get('mkt_niche') if inputs.get('mkt_niche') else None\n","    }\n","    # Check if *all* are None before setting the whole object to None\n","    # We want to keep partially filled goals for the strategist agent\n","    if all(v is None for v in marketing_goals_data.values()):\n","        marketing_goals_data = None # Set to None only if completely empty\n","\n","    # Get selected platform details (including resolution)\n","    selected_platform_key = inputs.get('platform')\n","    platform_details = SOCIAL_MEDIA_PLATFORMS.get(selected_platform_key) # Get the dict value\n","\n","    output_json = {\n","      \"request_details\": {\n","        \"mode\": mode.lower().replace(\" \", \"_\"), # e.g., \"custom_mode\"\n","        \"task_type\": inputs.get('task_type', None) if mode == 'Task-Specific Mode' else None,\n","        \"target_platform\": { # Store platform name and details\n","            \"name\": selected_platform_key,\n","            \"resolution\": platform_details # Contains width, height, aspect_ratio or None\n","        }\n","      },\n","      \"user_inputs\": {\n","        \"prompt\": inputs.get('prompt', None),\n","        \"image_reference\": image_ref_data, # Use the structured image data or None\n","        \"branding_elements\": inputs.get('branding', None),\n","        \"task_description\": inputs.get('task_content', None),\n","        \"marketing_goals\": marketing_goals_data # Store user-provided goals (potentially partial or None)\n","      },\n","      \"processing_context\": {\n","          \"initial_json_valid\": None, # To be filled later\n","          \"image_analysis_result\": None, # To store analysis output\n","          \"suggested_marketing_strategies\": None, # To store strategist output\n","          \"llm_call_usage\": {} # To store token usage\n","      }\n","    }\n","\n","    return output_json\n","\n","def parse_and_validate_json(generated_json):\n","    \"\"\"\n","    Simulates parsing and structural validation of the generated JSON (Simulates Server-Side).\n","    Checks if the received JSON structure is as expected.\n","    \"\"\"\n","    try:\n","        # Check top-level keys\n","        if not all(k in generated_json for k in [\"request_details\", \"user_inputs\", \"processing_context\"]):\n","            raise ValueError(\"Missing required top-level keys (request_details, user_inputs, processing_context).\")\n","\n","        request_details = generated_json.get(\"request_details\", {})\n","        user_inputs = generated_json.get(\"user_inputs\", {})\n","\n","        # Validate request_details\n","        mode = request_details.get(\"mode\").replace(\"-\",\"_\")\n","        platform_info = request_details.get(\"target_platform\") # Now an object\n","        platform_name = platform_info.get(\"name\") if isinstance(platform_info, dict) else None\n","\n","        if not mode or not platform_info or not platform_name:\n","             raise ValueError(\"Missing essential keys in request_details: mode or target_platform object/name.\")\n","        if platform_name == PLATFORM_DISPLAY_NAMES[0]: # Check placeholder name wasn't passed\n","             raise ValueError(\"Invalid target_platform name found in request_details.\")\n","        # Check if resolution exists and is a dictionary (or None if placeholder was somehow passed)\n","        resolution = platform_info.get(\"resolution\")\n","        if resolution is not None and not isinstance(resolution, dict):\n","             raise ValueError(\"Invalid target_platform resolution format found in request_details.\")\n","\n","        # --- FIXED MODE VALIDATION ---\n","        # Check if the mode string is one of the expected values\n","        valid_modes = [\"custom_mode\", \"task_specific_mode\"]\n","        if mode not in valid_modes:\n","            # This error message will now correctly trigger if the mode string is unexpected\n","            raise ValueError(f\"Unknown mode '{mode}' found in request_details. Expected one of {valid_modes}.\")\n","\n","        # Validate user_inputs based on the now confirmed valid mode\n","        if mode == \"custom_mode\":\n","            # Custom mode needs either prompt or image_reference\n","            if user_inputs.get(\"prompt\") is None and user_inputs.get(\"image_reference\") is None:\n","                raise ValueError(\"Custom mode JSON requires 'prompt' or 'image_reference' in user_inputs.\")\n","        elif mode == \"task_specific_mode\":\n","             # Task-specific mode needs a task_type\n","             task_type = request_details.get(\"task_type\")\n","             if not task_type:\n","                 raise ValueError(\"Task-specific mode JSON requires 'task_type' in request_details.\")\n","             if task_type == TASK_TYPES[0]: # Check placeholder task type wasn't passed\n","                 raise ValueError(\"Invalid task_type value found in request_details.\")\n","             # Add checks for mandatory task_description based on task_type if needed\n","             # Example:\n","             # if request_details.get('task_type') == '2. Promotional Graphics & Announcements' and not user_inputs.get('task_description'):\n","             #     raise ValueError(\"Promotional Graphics task JSON requires 'task_description'.\")\n","        # No else needed here because we already validated the mode string above\n","\n","        # Validate image_reference structure if it exists\n","        image_ref = user_inputs.get(\"image_reference\")\n","        if image_ref is not None:\n","            if not isinstance(image_ref, dict):\n","                 raise ValueError(\"user_inputs.image_reference must be an object (dict).\")\n","            if not all(k in image_ref for k in [\"filename\", \"content_type\", \"size_bytes\"]):\n","                 raise ValueError(\"user_inputs.image_reference is missing required keys (filename, content_type, size_bytes).\")\n","            # Could add type checks for size_bytes (int), content_type (str), etc.\n","\n","        # Validate marketing_goals structure if it exists\n","        mkt_goals = user_inputs.get(\"marketing_goals\")\n","        # It's okay for marketing_goals to be None initially\n","        if mkt_goals is not None and not isinstance(mkt_goals, dict):\n","             raise ValueError(\"user_inputs.marketing_goals must be an object (dict) or None.\")\n","             # Could check keys within marketing_goals if needed and not None\n","\n","        generated_json[\"processing_context\"][\"initial_json_valid\"] = True\n","        return True, \"Server-Side Validation: JSON structure seems valid.\"\n","    except Exception as e:\n","        generated_json[\"processing_context\"][\"initial_json_valid\"] = False\n","        return False, f\"Server-Side Validation Error: {e}\""]},{"cell_type":"code","execution_count":9,"metadata":{"id":"_9ImzWiNh2qC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746365486830,"user_tz":-480,"elapsed":81,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"}},"outputId":"f1ab89bd-d75e-428b-a988-3465af77d650"},"outputs":[{"output_type":"stream","name":"stdout","text":["Pydantic models 'ImageAnalysisResult', 'RelevantNicheList', 'MarketingGoalSetStage2', 'MarketingStrategyOutputStage2', and 'MarketingGoalSetFinal' defined.\n"]}],"source":["# @title Step 5: Define Pydantic Models (Image Analysis & Marketing Strategy)\n","\n","# Define the Pydantic model only if BaseModel was imported successfully\n","if BaseModel:\n","    class ImageAnalysisResult(BaseModel):\n","        \"\"\"Structured result of the image analysis.\"\"\"\n","        main_subject: str = Field(..., description=\"The single, primary subject of the image (e.g., 'Gourmet Burger', 'Latte Art', 'Restaurant Interior'). Should be concise.\")\n","        secondary_elements: Optional[List[str]] = Field(None, description=\"(Only if requested by instruction) List other notable objects or elements present.\")\n","        setting_environment: Optional[str] = Field(None, description=\"(Only if requested by instruction) Describe the background or setting.\")\n","        style_mood: Optional[str] = Field(None, description=\"(Only if requested by instruction) Describe the inferred visual style, mood, or atmosphere.\")\n","        extracted_text: Optional[str] = Field(None, description=\"(Only if requested by instruction) Extract any visible text from the image.\")\n","        suggested_keywords: Optional[List[str]] = Field(None, description=\"(Optional) List 3-5 relevant keywords for tagging.\")\n","\n","    # Model for Stage 1: Identifying relevant niches\n","    class RelevantNicheList(BaseModel):\n","        \"\"\"Identifies a list of relevant F&B niches for the given context.\"\"\"\n","        relevant_niches: List[str] = Field(..., description=\"A list of 3-5 diverse but highly relevant F&B niches based on the input context (e.g., ['Ethnic Cuisine (Thai)', 'Casual Dining', 'Takeaway/Delivery Focused']). Prioritize niches directly related to the image subject or task description.\")\n","        # justification: Optional[str] = Field(None, description=\"Brief overall justification for choosing these niches.\") # Optional justification\n","\n","    # Model for Stage 2: Generating goals based on a chosen niche\n","    class MarketingGoalSetStage2(BaseModel):\n","        \"\"\"Represents a set of marketing goals (audience, objective, voice) aligned with a specific niche.\"\"\"\n","        target_audience: str = Field(..., description=\"Specific target audience group, generated based on context and relevant to the predetermined niche.\")\n","        target_objective: str = Field(..., description=\"The primary marketing objective for this asset, generated based on context and relevant to the predetermined niche/task.\")\n","        target_voice: str = Field(..., description=\"The desired brand voice or tone, generated based on context and relevant to the predetermined niche/audience.\")\n","\n","    class MarketingStrategyOutputStage2(BaseModel):\n","         \"\"\"Container for N suggested marketing goal combinations (audience, objective, voice).\"\"\"\n","         strategies: List[MarketingGoalSetStage2] = Field(..., description=\"A list of N diverse and strategically sound marketing goal combinations (audience, objective, voice) aligned with a predetermined niche.\")\n","\n","    # Final structure stored in JSON context (includes niche)\n","    class MarketingGoalSetFinal(BaseModel):\n","        \"\"\"Represents a complete set of marketing goals for a creative direction.\"\"\"\n","        target_audience: str\n","        target_niche: str\n","        target_objective: str\n","        target_voice: str\n","\n","\n","    print(\"Pydantic models 'ImageAnalysisResult', 'RelevantNicheList', 'MarketingGoalSetStage2', 'MarketingStrategyOutputStage2', and 'MarketingGoalSetFinal' defined.\")\n","else:\n","    ImageAnalysisResult = None\n","    RelevantNicheList = None # New model name\n","    MarketingGoalSetStage2 = None\n","    MarketingStrategyOutputStage2 = None\n","    MarketingGoalSetFinal = None # Need to handle this in fallback too\n","    print(\"Pydantic not available, cannot define models.\")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"xf0CeuGwa6ZN","executionInfo":{"status":"ok","timestamp":1746365486913,"user_tz":-480,"elapsed":82,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"}}},"outputs":[],"source":["# @title Step 6: Perform Image Evaluation (Simulated/LLM with Pydantic)\n","\n","def perform_image_evaluation(generated_json):\n","    \"\"\"\n","    Performs image analysis using a VLM via OpenRouter (with Instructor/Pydantic)\n","    if configured, otherwise simulates the analysis. Focuses on the main subject\n","    unless instructed otherwise. Includes retries and token usage.\n","    Returns a status code: 'SUCCESS', 'API_ERROR', 'SIMULATED_NO_API', 'SIMULATED_FALLBACK', 'NO_IMAGE'.\n","    \"\"\"\n","    image_ref = generated_json.get(\"user_inputs\", {}).get(\"image_reference\")\n","    analysis_result = None\n","    status_message = \"No image provided for evaluation.\"\n","    usage_info = None # To store token usage\n","    status_code = 'NO_IMAGE' # Default status\n","\n","    if not image_ref: # No image uploaded\n","        generated_json[\"processing_context\"][\"image_analysis_result\"] = None\n","        return status_message, None, usage_info, status_code\n","\n","    filename = image_ref.get(\"filename\")\n","    instruction = image_ref.get(\"instruction\") # User's specific instruction\n","    content_type = image_ref.get(\"content_type\")\n","    size = image_ref.get(\"size_bytes\")\n","    image_content_base64 = image_ref.get(\"image_content_base64\") # Get base64 content if stored\n","\n","    task_type = generated_json.get(\"request_details\", {}).get(\"task_type\", \"N/A\")\n","    platform = generated_json.get(\"request_details\", {}).get(\"target_platform\", {}).get(\"name\", \"N/A\")\n","\n","    status_prefix = f\"Image '{filename}' ({content_type}, {size} bytes): \"\n","\n","    # Determine analysis scope based on instruction\n","    analysis_scope_instruction = \"Your primary goal is to identify the `main_subject` concisely.\"\n","    if instruction:\n","        analysis_scope_instruction = f\"Follow the user's instruction: '{instruction}'. If the instruction asks for more details (like style, setting, secondary elements, text extraction), provide them concisely in the relevant fields of the response model. Otherwise, focus ONLY on the `main_subject`.\"\n","    else:\n","        analysis_scope_instruction += \" No specific user instruction was provided.\"\n","\n","\n","    # --- Attempt LLM/VLM Call via OpenRouter using Instructor ---\n","    # Use the globally configured 'instructor_client' variable from Step 3\n","    if instructor_client and ImageAnalysisResult: # Check if instructor client and Pydantic model are available\n","        print(f\"(Attempting VLM call via OpenRouter/Instructor for image '{filename}'...)\")\n","        try:\n","            # --- VLM Prompt Engineering ---\n","            # Construct messages list for multimodal input\n","            prompt_messages = []\n","            user_content = [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": f\"\"\"Analyze the provided image for an F&B marketing task.\n","                            Context: Task='{task_type}', Target Platform='{platform}'.\n","                            {analysis_scope_instruction}\n","\n","                            Provide the analysis based on the requested `ImageAnalysisResult` response model. Be concise.\"\"\"\n","                }\n","            ]\n","\n","            # ** Add Image Data **\n","            if image_content_base64:\n","                 user_content.append({\n","                     \"type\": \"image_url\",\n","                     \"image_url\": {\n","                         # Use base64 data URI format\n","                         \"url\": f\"data:{content_type};base64,{image_content_base64}\"\n","                      }\n","                 })\n","            else:\n","                 # If base64 content isn't available, we cannot make a true VLM call\n","                 raise ValueError(\"Image content (base64) is missing for VLM analysis.\")\n","\n","\n","            prompt_messages = [\n","                {\n","                    \"role\": \"system\",\n","                    \"content\": \"You are an expert visual analyst for F&B marketing. Provide concise, structured analysis matching the requested Pydantic model.\"\n","                },\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": user_content # Pass the list containing text and image data\n","                }\n","            ]\n","\n","            print(f\"  Sending request to model: {IMG_EVAL_MODEL}\")\n","            completion = instructor_client.chat.completions.create(\n","                model=IMG_EVAL_MODEL,\n","                response_model=ImageAnalysisResult,\n","                messages=prompt_messages,\n","                temperature=0.3,\n","                max_tokens=400,\n","            )\n","            analysis_result_object = completion\n","\n","            raw_response = getattr(completion, '_raw_response', None)\n","            if raw_response and hasattr(raw_response, 'usage') and raw_response.usage:\n","                usage_info = raw_response.usage.model_dump()\n","                print(f\"  Token Usage (Image Eval): {usage_info}\")\n","            else:\n","                 print(\"  Token usage data not directly available from response object.\")\n","\n","            analysis_result = analysis_result_object.model_dump()\n","            print(f\"  Successfully received and validated Pydantic response from VLM.\")\n","            status_message = status_prefix + \"Analysis complete (via VLM/Instructor).\"\n","            status_code = 'SUCCESS' # API call was successful\n","\n","\n","        except ValueError as ve:\n","             print(f\"  ERROR preparing VLM call: {ve}\")\n","             status_message = status_prefix + f\"Analysis skipped ({ve}). Falling back to simulation.\"\n","             analysis_result = simulate_image_evaluation_fallback(instruction).model_dump()\n","             status_code = 'SIMULATED_FALLBACK' # Fallback due to internal error\n","\n","        # Catch specific OpenAI/HTTP errors if needed\n","        except (APIConnectionError, RateLimitError, APIStatusError) as api_error:\n","             print(f\"  ERROR: API call failed: {api_error}\")\n","             status_message = status_prefix + f\"Analysis failed ({type(api_error).__name__}). Falling back to simulation.\"\n","             analysis_result = simulate_image_evaluation_fallback(instruction).model_dump()\n","             status_code = 'API_ERROR' # Indicate API call failed\n","        except Exception as e: # Catch other potential errors (e.g., validation errors from Instructor)\n","            if RetryError and isinstance(e, RetryError):\n","                 print(f\"  ERROR: LLM call failed after {MAX_LLM_RETRIES + 1} attempts. Cause: {e.last_attempt.exception()}\")\n","                 status_message = status_prefix + f\"Analysis failed after retries ({e.last_attempt.exception()}). Falling back to simulation.\"\n","                 status_code = 'API_ERROR' # Indicate API call failed after retries\n","            else:\n","                 print(f\"  ERROR during OpenRouter/Instructor API call: {e}\")\n","                 status_message = status_prefix + f\"Analysis failed (API/Validation Error: {e}). Falling back to simulation.\"\n","                 status_code = 'API_ERROR' # Indicate other API/Validation error\n","            print(traceback.format_exc())\n","            analysis_result = simulate_image_evaluation_fallback(instruction).model_dump()\n","\n","    else: # Fallback if OpenRouter client or Pydantic is not configured\n","         print(\"(OpenRouter/Instructor client or Pydantic not configured, using basic simulation for image evaluation)\")\n","         analysis_result = simulate_image_evaluation_fallback(instruction).model_dump()\n","         status_message = status_prefix + \"Analysis simulated (No API Key / Library).\"\n","         status_code = 'SIMULATED_NO_API' # Indicate simulation due to config\n","\n","    # Store the result (dict) in the main JSON\n","    generated_json[\"processing_context\"][\"image_analysis_result\"] = analysis_result\n","    # Store usage info if available\n","    if usage_info:\n","        generated_json[\"processing_context\"][\"llm_call_usage\"][\"image_eval\"] = usage_info\n","\n","    return status_message, analysis_result, usage_info, status_code # Return status code\n","\n","def simulate_image_evaluation_fallback(instruction):\n","    \"\"\"\n","    Provides a simulated structured analysis (as a Pydantic object)\n","    when LLM call is not possible.\n","    \"\"\"\n","    if not ImageAnalysisResult: # Check if Pydantic model is defined\n","         # Return a simple dict if Pydantic model isn't available\n","         return {\"error\": \"Pydantic model not defined\", \"main_subject\": \"Simulated Subject (No Pydantic)\"}\n","\n","    data = {\n","            \"main_subject\": \"Identified Subject (Simulated e.g., Burger)\",\n","            \"secondary_elements\": None,\n","            \"setting_environment\": None,\n","            \"style_mood\": None,\n","            \"extracted_text\": None,\n","            \"suggested_keywords\": [\"simulated\", \"generic\", \"subject\", \"food\", \"fallback\"]\n","        }\n","    if instruction:\n","         # Simulate instruction influencing the subject\n","        data[\"main_subject\"] = f\"Subject based on instruction (Simulated)\"\n","        # Optionally simulate filling other fields if instruction implies it\n","        if \"style\" in instruction.lower():\n","            data[\"style_mood\"] = \"Simulated style based on instruction\"\n","        if \"setting\" in instruction.lower():\n","             data[\"setting_environment\"] = \"Simulated setting based on instruction\"\n","        if \"text\" in instruction.lower():\n","             data[\"extracted_text\"] = \"Simulated extracted text\"\n","        if \"element\" in instruction.lower() or \"object\" in instruction.lower():\n","             data[\"secondary_elements\"] = [\"Simulated element 1\", \"Simulated element 2\"]\n","\n","\n","    # Create and return a Pydantic object\n","    try:\n","      return ImageAnalysisResult(**data)\n","    except Exception as e:\n","        print(f\"Error creating fallback Pydantic object: {e}\")\n","        # Return dict on error creating Pydantic obj\n","        return {\"error\": \"Fallback object creation failed\", \"main_subject\": \"Simulated Subject (Error)\"}\n","\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"6lPkD2MBbWe2","executionInfo":{"status":"ok","timestamp":1746365487096,"user_tz":-480,"elapsed":144,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"}}},"outputs":[],"source":["# @title Step 7: Generate Marketing Strategies (Simulated/LLM with Pydantic - Staged Reasoning) - MODIFIED STEP\n","\n","def generate_marketing_strategies(generated_json, num_strategies: int = 3):\n","    \"\"\"\n","    Generates N diverse marketing strategy combinations using a STAGED LLM approach\n","    if the user hasn't provided complete goals.\n","    Stage 1: Identify a list of relevant niches.\n","    Stage 2: Generate combinations based on identified niches and other context.\n","    Includes retries and token usage.\n","    \"\"\"\n","    user_goals = generated_json.get(\"user_inputs\", {}).get(\"marketing_goals\") # Can be None or dict\n","    # Check if user provided all goals (handle None case and empty strings)\n","    user_goals_complete = False\n","    if user_goals:\n","         user_goals_complete = all(user_goals.get(k) for k in ['target_audience', 'objective', 'voice', 'niche']) # Checks for non-empty values\n","\n","    status_message = \"User provided complete marketing goals. Skipping strategy generation.\"\n","    suggested_strategies = None # Will hold list of dicts\n","    usage_info_stage1 = None\n","    usage_info_stage2 = None\n","    status_code = 'SKIPPED' # Default status\n","\n","    if user_goals_complete:\n","        print(status_message)\n","        # Store the user's single complete goal set as the only strategy\n","        generated_json[\"processing_context\"][\"suggested_marketing_strategies\"] = [user_goals]\n","        return status_message, [user_goals], None, None, status_code # Return None for usage\n","\n","    # Proceed if goals are incomplete or not provided\n","    status_message = f\"Generating {num_strategies} marketing strategy suggestions...\"\n","    print(status_message) # Print status immediately\n","\n","    # --- Extract relevant context for the strategist ---\n","    task_type = generated_json.get(\"request_details\", {}).get(\"task_type\", \"N/A\")\n","    platform = generated_json.get(\"request_details\", {}).get(\"target_platform\", {}).get(\"name\", \"N/A\")\n","    user_prompt = generated_json.get(\"user_inputs\", {}).get(\"prompt\") # Can be None\n","    task_description = generated_json.get(\"user_inputs\", {}).get(\"task_description\") # Can be None\n","    image_analysis = generated_json.get(\"processing_context\", {}).get(\"image_analysis_result\") # Can be None or dict\n","    image_subject = \"N/A\"\n","    if isinstance(image_analysis, dict):\n","        # Avoid passing error messages as subject\n","        if \"error\" not in image_analysis:\n","             image_subject = image_analysis.get(\"main_subject\", \"N/A\")\n","        else:\n","             image_subject = \"Analysis Failed\"\n","\n","    # --- Select Task-Specific Pools (for Stage 2 fallback/inspiration) ---\n","    task_pools = get_pools_for_task(task_type)\n","    audience_pool = task_pools.get(\"audience\", TASK_GROUP_POOLS[\"default\"][\"audience\"])\n","    niche_pool_inspiration = task_pools.get(\"niche\", TASK_GROUP_POOLS[\"default\"][\"niche\"]) # For fallback/inspiration only\n","    objective_pool = task_pools.get(\"objective\", TASK_GROUP_POOLS[\"default\"][\"objective\"])\n","    voice_pool = task_pools.get(\"voice\", TASK_GROUP_POOLS[\"default\"][\"voice\"])\n","\n","    # --- STAGE 1: Identify Relevant Niches ---\n","    identified_niches = [] # Now a list\n","    stage1_status = \"Starting Niche Identification...\"\n","    print(f\"  Stage 1: {stage1_status}\")\n","    stage1_status_code = 'INIT'\n","    num_niches_to_find = random.randint(3, 5) # Target 3-5 niches\n","\n","    # Use user-provided niche if available as the *only* niche\n","    user_provided_niche = (user_goals or {}).get('target_niche')\n","    if user_provided_niche:\n","        identified_niches = [user_provided_niche]\n","        stage1_status = f\"Using user-provided niche: '{identified_niches[0]}'.\"\n","        print(f\"    Status: {stage1_status}\")\n","        stage1_status_code = 'USER_PROVIDED'\n","\n","        stage1_status = f\"Using user-provided niche: '{identified_niches[0]}'.\"\n","        print(f\"    Status: {stage1_status}\")\n","        stage1_status_code = 'USER_PROVIDED'\n","    elif instructor_client and RelevantNicheList: # Check dependencies\n","        try:\n","            print(f\"    (Attempting LLM call for {num_niches_to_find} Niche Identifications...)\")\n","            niche_system_prompt = f\"\"\"You are an expert F&B market analyst. Your task is to identify {num_niches_to_find} diverse but MOST relevant F&B niches for the given context. Consider the image subject, task description, and task type. Prioritize the most logical fits based on the context. Output ONLY the Pydantic `RelevantNicheList` object containing the list of niche names.\"\"\"\n","            niche_user_prompt = f\"\"\"Identify {num_niches_to_find} diverse but relevant F&B niches for this context:\n","Task Type: {task_type or 'N/A'}\n","Task-Specific Content/Description: {task_description or 'Not Provided'}\n","Identified Image Subject: {image_subject or 'Not Provided / Not Applicable'}\n","User-Provided Niche (Use if provided): {(user_goals or {}).get('target_niche') or 'Not Provided'}\n","\n","Determine the {num_niches_to_find} best `relevant_niches` based on the context, especially the image subject.\"\"\"\n","\n","            completion_niche = instructor_client.chat.completions.create(\n","                model=STRATEGY_MODEL, # Or a more capable model\n","                response_model=RelevantNicheList, # Use the new list model\n","                messages=[\n","                    {\"role\": \"system\", \"content\": niche_system_prompt},\n","                    {\"role\": \"user\", \"content\": niche_user_prompt}\n","                ],\n","                temperature=0.5, # Allow some diversity in niche selection\n","                max_tokens=200,\n","            )\n","            niche_list_object = completion_niche\n","\n","            # Try to access usage data\n","            raw_response_niche = getattr(completion_niche, '_raw_response', None)\n","            if raw_response_niche and hasattr(raw_response_niche, 'usage') and raw_response_niche.usage:\n","                usage_info_stage1 = raw_response_niche.usage.model_dump()\n","                print(f\"    Token Usage (Niche ID): {usage_info_stage1}\")\n","            else:\n","                 print(\"    Token usage data not directly available from niche response object.\")\n","\n","\n","            identified_niches = niche_list_object.relevant_niches # Get the list\n","            stage1_status = f\"Niches identified via LLM: {identified_niches}\"\n","            print(f\"    Status: {stage1_status}\")\n","            stage1_status_code = 'SUCCESS'\n","\n","        except Exception as e:\n","            print(f\"    ERROR during Niche Identification LLM call: {e}\")\n","            stage1_status = \"Niche Identification LLM call failed. Falling back to simulation.\"\n","            print(f\"    Status: {stage1_status}\")\n","            # Fallback niche selection\n","            identified_niches = random.sample(niche_pool_inspiration, min(num_niches_to_find, len(niche_pool_inspiration)))\n","            stage1_status_code = 'API_ERROR'\n","\n","\n","    else: # Fallback if client/Pydantic not available\n","        stage1_status = \"Niche Identification skipped (Client/Pydantic unavailable). Using simulation.\"\n","        print(f\"  Stage 1: {stage1_status}\")\n","        identified_niches = random.sample(niche_pool_inspiration, min(num_niches_to_find, len(niche_pool_inspiration)))\n","        stage1_status_code = 'SIMULATED_NO_API'\n","\n","    if not identified_niches: # Ensure we always have at least one niche for stage 2\n","         print(\"    WARNING: No niches identified or simulated, using default.\")\n","         identified_niches = [random.choice(niche_pool_inspiration)]\n","         stage1_status += \" (Used default niche as fallback)\"\n","\n","    print(f\"  Using Niches: {identified_niches} for strategy generation.\")\n","\n","    # --- STAGE 2: Generate Goal Combinations based on Identified Niches ---\n","    stage2_status = \"Starting Goal Combination Generation...\"\n","    print(f\"  Stage 2: {stage2_status}\")\n","    stage2_status_code = 'INIT'\n","    suggested_strategies = [] # Initialize list for final combined strategies\n","\n","    if instructor_client and MarketingStrategyOutputStage2 and MarketingGoalSetStage2 and MarketingGoalSetFinal: # Check dependencies\n","        try:\n","            print(\"    (Attempting LLM call for Goal Combinations...)\")\n","            # --- Strategist Prompt Engineering (Stage 2 - Refined) ---\n","            system_prompt_stage2 = f\"\"\"You are an expert F&B Marketing Strategist. Your goal is to generate {num_strategies} diverse and strategically sound marketing goal combinations (audience, objective, voice).\n","For each combination:\n","1.  Select ONE niche from the provided 'Relevant Niches List'. Aim to use different niches from the list across the {num_strategies} combinations for diversity, unless the user provided a specific niche (in which case, use that one).\n","2.  Generate a fitting `target_audience`, `target_objective`, and `target_voice` that logically align with the **chosen niche** for that specific combination and the overall context (task type, image subject).\n","**Handling User Input:**\n","- If the user provided a value for audience, objective, or voice, incorporate **relevant variations** of that theme into the generated combinations where it logically fits the chosen niche for that strategy. For example, if the user objective is 'increase sales', generated objectives could be 'Drive Short-Term Sales', 'Boost Online Orders', 'Increase Average Order Value', etc., all related to increasing sales and fitting the chosen niche. Do not just copy the user input verbatim unless it's the best fit.\n","- For goals the user did *not* provide, generate appropriate values based on the context, chosen niche, and user-provided goals (if any).\n","Ensure the {num_strategies} generated combinations are distinct from each other and make sense. Try to use different niches from the provided list across the strategies for diversity.\n","Output the result matching the `MarketingStrategyOutputStage2` model containing a list of exactly {num_strategies} `MarketingGoalSetStage2` objects (audience, objective, voice ONLY). **Ensure each item in the list is a valid JSON object.**\"\"\"\n","\n","            # User prompt now includes the list of identified niches\n","            user_prompt_context_stage2 = f\"\"\"Generate {num_strategies} diverse marketing strategy combinations (audience, objective, voice) for the following F&B task. For each strategy, choose a relevant niche from the list provided below and ensure the generated goals align with it.\n","Task Type: {task_type or 'N/A'}\n","Target Platform: {platform or 'N/A'}\n","User's General Prompt: {user_prompt or 'Not Provided'}\n","Task-Specific Content/Description: {task_description or 'Not Provided'}\n","Identified Image Subject: {image_subject or 'Not Provided / Not Applicable'}\n","\n","**Relevant Niches List (Choose one niche from this list for each strategy):** {identified_niches}\n","\n","User-Provided Goals (Use as strong guidelines/constraints for generated values):\n","Audience: {(user_goals or {}).get('target_audience') or 'Not Provided'}\n","Objective: {(user_goals or {}).get('target_objective') or 'Not Provided'}\n","Voice: {(user_goals or {}).get('target_voice') or 'Not Provided'}\n","(User-provided Niche '{user_provided_niche}' influenced the Relevant Niches List above).\n","\n","Generate {num_strategies} complete, diverse, and strategically relevant `MarketingGoalSetStage2` combinations (audience, objective, voice only). Ensure logical consistency with the chosen niche from the list and overall context. **Adhere strictly to the output format (list of JSON objects).**\"\"\"\n","\n","            prompt_messages_stage2 = [\n","                {\"role\": \"system\", \"content\": system_prompt_stage2},\n","                {\"role\": \"user\", \"content\": user_prompt_context_stage2}\n","            ]\n","\n","            #llm_model = \"openai/gpt-4o-mini\" # Or a more capable model\n","\n","            print(f\"    Sending request to model: {STRATEGY_MODEL}\")\n","            completion_stage2 = instructor_client.chat.completions.create(\n","                model=STRATEGY_MODEL,\n","                response_model=MarketingStrategyOutputStage2, # Use Stage 2 Pydantic model\n","                messages=prompt_messages_stage2,\n","                temperature=0.7,\n","                max_tokens=1500, # Keep increased max_tokens\n","            )\n","            strategy_output_object_stage2 = completion_stage2\n","\n","            # Try to access usage data\n","            raw_response_strat = getattr(completion_stage2, '_raw_response', None)\n","            if raw_response_strat and hasattr(raw_response_strat, 'usage') and raw_response_strat.usage:\n","                usage_info_stage2 = raw_response_strat.usage.model_dump()\n","                print(f\"    Token Usage (Goal Combos): {usage_info_stage2}\")\n","            else:\n","                 print(\"    Token usage data not directly available from goal combo response object.\")\n","\n","            # Convert the list of Pydantic objects to a list of dicts for storing\n","            # Add the assigned niche back into each strategy dict\n","            temp_suggested_strategies = []\n","            for i, strategy_stage2 in enumerate(strategy_output_object_stage2.strategies):\n","                strategy_dict = strategy_stage2.model_dump()\n","                # Assign niche - cycle through identified niches or use user's\n","                assigned_niche = user_provided_niche if user_provided_niche else identified_niches[i % len(identified_niches)]\n","                strategy_dict['target_niche'] = assigned_niche\n","\n","                # *** Override other fields if user provided them ***\n","                if (user_goals or {}).get('target_audience'):\n","                    strategy_dict['target_audience'] = user_goals['target_audience'] # Or generate variation if needed\n","                if (user_goals or {}).get('target_objective'):\n","                    strategy_dict['target_objective'] = user_goals['target_objective'] # Or generate variation if needed\n","                if (user_goals or {}).get('target_voice'):\n","                    strategy_dict['target_voice'] = user_goals['target_voice'] # Or generate variation if needed\n","\n","                # Ensure all keys are present before appending\n","                if all(k in strategy_dict for k in ['target_audience', 'target_niche', 'target_objective', 'target_voice']):\n","                     # Validate final dict with the complete model before appending\n","                     try:\n","                          final_strategy_obj = MarketingGoalSetFinal(**strategy_dict)\n","                          temp_suggested_strategies.append(final_strategy_obj.model_dump())\n","                     except Exception as pydantic_error:\n","                          print(f\"    WARNING: Failed to validate final strategy structure: {strategy_dict}. Error: {pydantic_error}\")\n","                else:\n","                     print(f\"    WARNING: Incomplete strategy generated by LLM (missing keys before niche assignment): {strategy_stage2.model_dump()}\")\n","\n","            suggested_strategies = temp_suggested_strategies # Assign the final list\n","\n","\n","            # Validate if we got the requested number of strategies\n","            if len(suggested_strategies) != num_strategies:\n","                 print(f\"    WARNING: LLM generated {len(suggested_strategies)} valid strategies, but {num_strategies} were requested.\")\n","            else:\n","                 print(f\"    Successfully received and validated {len(suggested_strategies)} marketing strategies from LLM.\")\n","            stage2_status = \"Goal combinations generated successfully (via LLM/Instructor).\"\n","            stage2_status_code = 'SUCCESS'\n","\n","\n","        except APIConnectionError as e:\n","             print(f\"    ERROR: Failed to connect to OpenRouter API: {e}\")\n","             stage2_status = f\"Goal Combination generation failed (Connection Error). Falling back to simulation.\"\n","             suggested_strategies = simulate_marketing_strategy_fallback_staged(user_goals, identified_niches, task_type, num_strategies)\n","             stage2_status_code = 'API_ERROR'\n","        except RateLimitError as e:\n","             print(f\"    ERROR: OpenRouter Rate limit exceeded: {e}\")\n","             stage2_status = f\"Goal Combination generation failed (Rate Limit Error). Falling back to simulation.\"\n","             suggested_strategies = simulate_marketing_strategy_fallback_staged(user_goals, identified_niches, task_type, num_strategies)\n","             stage2_status_code = 'API_ERROR'\n","        except APIStatusError as e:\n","             print(f\"    ERROR: OpenRouter API returned an error status: {e.status_code} - {e.response}\")\n","             stage2_status = f\"Goal Combination generation failed (API Status Error {e.status_code}). Falling back to simulation.\"\n","             suggested_strategies = simulate_marketing_strategy_fallback_staged(user_goals, identified_niches, task_type, num_strategies)\n","             stage2_status_code = 'API_ERROR'\n","        except Exception as e: # Catch other potential errors\n","            print(f\"    ERROR during OpenRouter/Instructor API call for goal combinations: {e}\")\n","            print(traceback.format_exc()) # Print full traceback for debugging\n","            stage2_status = f\"Goal Combination generation failed (API/Validation Error: {e}). Falling back to simulation.\"\n","            suggested_strategies = simulate_marketing_strategy_fallback_staged(user_goals, identified_niches, task_type, num_strategies)\n","            stage2_status_code = 'API_ERROR'\n","\n","    else: # Fallback if OpenRouter client or Pydantic is not configured\n","         print(\"    (OpenRouter/Instructor client or Pydantic not configured, using basic simulation for goal combinations)\")\n","         suggested_strategies = simulate_marketing_strategy_fallback_staged(user_goals, identified_niches, task_type, num_strategies)\n","         stage2_status = \"Goal combinations simulated (No API Key / Library).\"\n","         stage2_status_code = 'SIMULATED_NO_API'\n","\n","    print(f\"  Stage 2: {stage2_status}\")\n","    # Store the final result (list of dicts) in the main JSON\n","    generated_json[\"processing_context\"][\"suggested_marketing_strategies\"] = suggested_strategies\n","    # Store usage info if available\n","    if usage_info_stage1: generated_json[\"processing_context\"][\"llm_call_usage\"][\"strategy_niche_id\"] = usage_info_stage1\n","    if usage_info_stage2: generated_json[\"processing_context\"][\"llm_call_usage\"][\"strategy_goal_gen\"] = usage_info_stage2\n","\n","    # Determine overall status code\n","    if stage1_status_code == 'API_ERROR' or stage2_status_code == 'API_ERROR':\n","        overall_status_code = 'API_ERROR'\n","    elif stage1_status_code == 'SIMULATED_NO_API' or stage2_status_code == 'SIMULATED_NO_API':\n","         overall_status_code = 'SIMULATED_NO_API'\n","    elif stage1_status_code in ['USER_PROVIDED', 'SUCCESS'] and stage2_status_code == 'SUCCESS':\n","         overall_status_code = 'SUCCESS'\n","    else: # Handle other combinations if necessary\n","         overall_status_code = 'UNKNOWN'\n","\n","\n","    overall_status_message = f\"Marketing strategies generated ({stage1_status.split('.')[0]}; {stage2_status.split('.')[0]})\"\n","    # Return combined usage info (or individual if preferred)\n","    combined_usage = {**(usage_info_stage1 or {}), **(usage_info_stage2 or {})} # Simple merge, might overwrite keys if same name\n","    return overall_status_message, suggested_strategies, combined_usage, overall_status_code # Return status code\n","\n","def simulate_marketing_strategy_fallback_staged(user_goals, identified_niches, task_type, num_strategies=3):\n","    \"\"\"\n","    Provides N simulated marketing strategies (list of dicts) for the staged approach,\n","    using the predetermined niche list.\n","    \"\"\"\n","    if not MarketingGoalSetFinal: # Check if Pydantic model is defined\n","        return [{\"error\": \"Pydantic model not defined, cannot simulate fallback strategies.\"}] * num_strategies\n","\n","    # Get task-specific pools for more relevant defaults (excluding niche)\n","    task_pools = get_pools_for_task(task_type)\n","    audience_pool = task_pools.get(\"audience\", TASK_GROUP_POOLS[\"default\"][\"audience\"])\n","    objective_pool = task_pools.get(\"objective\", TASK_GROUP_POOLS[\"default\"][\"objective\"])\n","    voice_pool = task_pools.get(\"voice\", TASK_GROUP_POOLS[\"default\"][\"voice\"])\n","\n","    strategies = []\n","    used_combinations = set() # To ensure some diversity based on audience/objective/voice\n","\n","    # Ensure identified_niches is a list and not empty\n","    if not isinstance(identified_niches, list) or not identified_niches:\n","        identified_niches = [random.choice(TASK_GROUP_POOLS[\"default\"][\"niche\"])]\n","\n","\n","    for i in range(num_strategies):\n","        # Cycle through identified niches for diversity\n","        current_niche = identified_niches[i % len(identified_niches)]\n","        # Override niche if user provided one\n","        if (user_goals or {}).get('target_niche'):\n","             current_niche = user_goals['target_niche']\n","\n","        current_goals = {\n","        \"target_audience\": (user_goals or {}).get('target_audience') or random.choice(audience_pool),\n","        \"target_niche\": current_niche, # Use the assigned/user niche\n","        \"target_objective\": (user_goals or {}).get('target_objective') or random.choice(objective_pool),\n","        \"target_voice\": (user_goals or {}).get('target_voice') or random.choice(voice_pool)\n","    }\n","\n","        # Ensure uniqueness for simulation (simple approach)\n","        combination_tuple = tuple([current_goals[\"target_audience\"], current_goals[\"target_objective\"], current_goals[\"target_voice\"], current_goals[\"target_niche\"]])\n","        attempts = 0\n","        while combination_tuple in used_combinations and attempts < 10: # Avoid infinite loop\n","             # Try changing objective first for variation\n","             current_goals[\"target_objective\"] = random.choice(objective_pool) + \" (Alt)\"\n","             combination_tuple = tuple([current_goals[\"target_audience\"], current_goals[\"target_objective\"], current_goals[\"target_voice\"], current_goals[\"target_niche\"]])\n","             attempts += 1\n","\n","        if combination_tuple not in used_combinations:\n","            try:\n","                 # Validate with Pydantic before adding, even in fallback\n","                 validated_goals = MarketingGoalSetFinal(**current_goals)\n","                 strategies.append(validated_goals.model_dump())\n","                 used_combinations.add(combination_tuple)\n","            except Exception as e:\n","                 print(f\"Error creating fallback strategy {i+1}: {e}\")\n","                 strategies.append({\"error\": f\"Fallback strategy {i+1} creation failed\", \"target_niche\": current_niche})\n","                 used_combinations.add(combination_tuple) # Add even if failed to avoid infinite loop\n","        elif len(strategies) < num_strategies: # Add placeholder if uniqueness failed after attempts\n","             strategies.append({\"error\": \"Could not generate unique fallback strategy\", \"target_niche\": current_niche})\n","\n","\n","    # If we still don't have enough, add duplicates (less ideal)\n","    while len(strategies) < num_strategies:\n","         if strategies: # Check if strategies list is not empty\n","            strategies.append(strategies[0])\n","         else: # If even the first strategy failed\n","            strategies.append({\"error\": \"Fallback failed completely\", \"target_niche\": identified_niches[0]})\n","\n","    return strategies\n","\n","\n","# --- Main Processing Function ---\n","def run_pipeline_processing():\n","    \"\"\"Gathers inputs, validates, generates JSON, and runs processing steps.\"\"\"\n","    # Add a timestamp to differentiate runs in logs\n","    run_timestamp_str = time.strftime(\"%Y%m%d_%H%M%S\") # Timestamp for filenames\n","    print(f\"\\n--- Starting Run: {run_timestamp_str} ---\")\n","\n","    # --- MODIFICATION: Clear output area before starting the processing inside it ---\n","    clear_output(wait=True)\n","    # --- END MODIFICATION ---\n","\n","    with output_area:\n","        # Using wait=True ensures it clears before new output appears\n","        # clear_output(wait=True) # Moved outside the 'with' block\n","        print(f\"Processing request... (Run started at {run_timestamp_str})\")\n","        final_json = None # Initialize\n","        total_usage = {} # To aggregate usage across steps\n","        saved_image_path_str = None # Initialize path for saved image\n","\n","        try:\n","            # 1. Gather Inputs\n","            print(\"--- Step 1: Gathering Inputs ---\")\n","            mode = mode_selection.value\n","            inputs = {\n","                'platform': platform_selection.value, # Get selected platform display name\n","                'prompt': prompt_input.value if prompt_input.value else None, # Store None if empty\n","                'image_widget_has_value': bool(image_upload.value) # Track if upload widget has data\n","            }\n","            print(\"  Inputs gathered (excluding image content).\")\n","\n","            # Handle image upload - Extract details AND content (Base64)\n","            uploaded_file_info = image_upload.value\n","            inputs['image_details'] = None # Initialize\n","            inputs['image_content_base64'] = None # Initialize\n","            image_content_bytes = None # Store bytes for saving later\n","\n","            if uploaded_file_info:\n","                try:\n","                    # Get the first uploaded file's info (since multiple=False)\n","                    first_file_key = list(uploaded_file_info.keys())[0]\n","                    metadata = uploaded_file_info[first_file_key]['metadata']\n","                    image_content_bytes = uploaded_file_info[first_file_key]['content'] # Read bytes\n","\n","                    inputs['image_details'] = {\n","                        'filename': metadata.get('name'),\n","                        'content_type': metadata.get('type'),\n","                        'size_bytes': metadata.get('size')\n","                    }\n","                    # Encode image content to Base64 for VLM API call\n","                    inputs['image_content_base64'] = base64.b64encode(image_content_bytes).decode('utf-8')\n","                    print(f\"  Image '{metadata.get('name')}' processed.\")\n","\n","                except Exception as e:\n","                    print(f\"  Error processing uploaded image details/content: {e}\")\n","                    # Keep image_details as None if error occurs\n","                    inputs['image_details'] = None\n","                    inputs['image_content_base64'] = None\n","            else:\n","                print(\"  No image uploaded.\")\n","\n","\n","            inputs['image_instruction'] = image_instruction.value if image_instruction.value else None\n","\n","\n","            if mode == 'Task-Specific Mode':\n","                inputs['task_type'] = task_selection.value # Get task type value\n","                inputs['branding'] = branding_elements_input.value if branding_elements_input.value else None\n","                inputs['task_content'] = task_description_input.value if task_description_input.value else None\n","                inputs['mkt_audience'] = marketing_audience.value if marketing_audience.value else None\n","                inputs['mkt_objective'] = marketing_objective.value if marketing_objective.value else None\n","                inputs['mkt_voice'] = marketing_voice.value if marketing_voice.value else None\n","                inputs['mkt_niche'] = marketing_niche.value if marketing_niche.value else None\n","\n","\n","            # 2. Validate Raw Inputs (Simulated Client-Side)\n","            print(\"\\n--- Step 2: Client-Side Input Validation ---\")\n","            is_valid, validation_msg = validate_inputs(mode, inputs)\n","            print(f\"Status: {validation_msg}\")\n","            if not is_valid:\n","                print(f\"--- Run ENDED (Validation Failed): {time.strftime('%Y-%m-%d %H:%M:%S')} ---\")\n","                return # Stop processing if basic inputs are invalid\n","\n","            # 3. Generate Initial JSON\n","            print(\"\\n--- Step 3: Generating Initial JSON ---\")\n","            generated_json = generate_initial_json(mode, inputs)\n","            # Don't print the base64 content in the main output for brevity\n","            generated_json_display = json.loads(json.dumps(generated_json)) # Deep copy\n","            if generated_json_display.get(\"user_inputs\",{}).get(\"image_reference\"):\n","                 if \"image_content_base64\" in generated_json_display[\"user_inputs\"][\"image_reference\"]:\n","                      del generated_json_display[\"user_inputs\"][\"image_reference\"][\"image_content_base64\"]\n","            print(json.dumps(generated_json_display, indent=2))\n","\n","            final_json = generated_json # Keep track of the latest JSON state\n","\n","            # 4. Parse and Validate JSON Structure (Simulated Server-Side)\n","            print(\"\\n--- Step 4: Server-Side JSON Validation ---\")\n","            json_ok, json_validation_msg = parse_and_validate_json(generated_json)\n","            print(f\"Status: {json_validation_msg}\")\n","            # Update JSON with validation status (already done inside the function)\n","            if not json_ok:\n","                print(\"\\nERROR: Server-side validation failed. Stopping processing.\")\n","                print(\"\\n--- Final JSON Output (Validation Failed) ---\")\n","                # Display without base64\n","                final_json_display = json.loads(json.dumps(final_json)) # Deep copy\n","                if final_json_display.get(\"user_inputs\",{}).get(\"image_reference\"):\n","                     if \"image_content_base64\" in final_json_display[\"user_inputs\"][\"image_reference\"]:\n","                          del final_json_display[\"user_inputs\"][\"image_reference\"][\"image_content_base64\"]\n","                print(json.dumps(final_json_display, indent=2))\n","                print(f\"--- Run ENDED (Validation Failed): {time.strftime('%Y-%m-%d %H:%M:%S')} ---\")\n","                return\n","\n","\n","            # 5. Perform Image Evaluation\n","            print(\"\\n--- Step 5: Image Evaluation ---\")\n","            eval_status, analysis_result, eval_usage, eval_status_code = perform_image_evaluation(generated_json) # Get status code\n","            if eval_usage: total_usage[\"image_eval\"] = eval_usage # Store usage\n","            print(f\"Status: {eval_status}\")\n","            # The analysis result (dict) is added to generated_json inside the function\n","            final_json = generated_json # Update final_json with analysis results\n","\n","            # --- MODIFIED: Check if image evaluation failed due to API error ---\n","            if eval_status_code == 'API_ERROR':\n","                 print(\"\\nERROR: Image Evaluation failed due to API error. Halting pipeline.\")\n","                 print(\"\\n--- Final JSON Output (Image Eval Failed) ---\")\n","                 # Display without base64\n","                 final_json_display = json.loads(json.dumps(final_json)) # Deep copy\n","                 if final_json_display.get(\"user_inputs\",{}).get(\"image_reference\"):\n","                      if \"image_content_base64\" in final_json_display[\"user_inputs\"][\"image_reference\"]:\n","                           del final_json_display[\"user_inputs\"][\"image_reference\"][\"image_content_base64\"]\n","                 print(json.dumps(final_json_display, indent=2))\n","                 print(f\"--- Run ENDED (Image Eval Failed): {time.strftime('%Y-%m-%d %H:%M:%S')} ---\")\n","                 return # Stop processing\n","\n","            # 6. Generate Marketing Strategies (Staged Approach)\n","            print(\"\\n--- Step 6: Marketing Strategy Generation ---\")\n","            # Define how many strategies to generate\n","            num_strategies_to_generate = 5 # Changed back to 5 as per user's previous output example\n","            strategy_status, suggested_strategies, strategy_usage, strategy_status_code = generate_marketing_strategies(generated_json, num_strategies=num_strategies_to_generate)\n","            # Store combined usage under a single key\n","            if strategy_usage: total_usage[\"strategy_gen_combined\"] = strategy_usage\n","            print(f\"Status: {strategy_status}\")\n","            # Strategies (list of dicts) are added to generated_json inside the function\n","\n","            final_json = generated_json # Update final_json with strategies\n","\n","            # Update total usage in the final JSON\n","            final_json[\"processing_context\"][\"llm_call_usage\"] = total_usage\n","\n","            print(\"\\n--- Final JSON Output (Before File Save) ---\")\n","             # Display without base64\n","            final_json_display = json.loads(json.dumps(final_json)) # Deep copy\n","            if final_json_display.get(\"user_inputs\",{}).get(\"image_reference\"):\n","                 if \"image_content_base64\" in final_json_display[\"user_inputs\"][\"image_reference\"]:\n","                      del final_json_display[\"user_inputs\"][\"image_reference\"][\"image_content_base64\"]\n","            # The analysis result and strategies are already dicts here\n","            print(json.dumps(final_json_display, indent=2))\n","\n","            # --- Step 7: Save Output Files ---\n","            print(\"\\n--- Step 7: Saving Output Files ---\")\n","            # MODIFIED: Use specified Google Drive path\n","            output_base_path = '/content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook'\n","            output_folder_name = 'pipeline_upstream_outputs'\n","            output_dir = pathlib.Path(output_base_path) / output_folder_name\n","            # END MODIFICATION\n","\n","            # Ensure the directory exists (create if not) - requires Drive mounted\n","            try:\n","                output_dir.mkdir(parents=True, exist_ok=True) # Create directory if it doesn't exist\n","                print(f\"  Output directory: {output_dir}\")\n","            except Exception as dir_error:\n","                print(f\"  ERROR creating output directory '{output_dir}': {dir_error}\")\n","                print(\"  Please ensure Google Drive is mounted and the path is accessible.\")\n","                print(\"  Skipping file saving.\")\n","                # Optionally end execution if saving is critical\n","                # print(f\"--- Run ENDED (Directory Error): {time.strftime('%Y-%m-%d %H:%M:%S')} ---\")\n","                # return\n","\n","            # Create unique base filename using the run's timestamp string\n","            base_filename = f\"output_{run_timestamp_str}\"\n","\n","            # Save Image if exists\n","            saved_image_filename = None\n","            if image_content_bytes and final_json.get(\"user_inputs\", {}).get(\"image_reference\"):\n","                try:\n","                    image_ref = final_json[\"user_inputs\"][\"image_reference\"]\n","                    content_type = image_ref.get(\"content_type\")\n","                    # Force JPEG extension\n","                    extension = \".jpeg\"\n","                    # Sanitize original filename or use a standard name\n","                    original_filename_stem = pathlib.Path(image_ref.get(\"filename\", \"input_image\")).stem\n","                    # Replace spaces or invalid chars in filename stem if needed\n","                    safe_stem = \"\".join(c if c.isalnum() or c in ('-', '_') else '_' for c in original_filename_stem)\n","                    saved_image_filename = f\"{safe_stem}_{run_timestamp_str}{extension}\"\n","                    saved_image_path = output_dir / saved_image_filename\n","\n","                    # Use Pillow to open and save as JPEG, handling transparency\n","                    img = Image.open(io.BytesIO(image_content_bytes))\n","                    if img.mode in ('RGBA', 'LA', 'P'):\n","                        background = Image.new('RGB', img.size, (255, 255, 255))\n","                        background.paste(img, (0, 0), img.split()[-1] if len(img.split()) == 4 else None)\n","                        img = background\n","                    elif img.mode != 'RGB':\n","                        img = img.convert('RGB')\n","\n","                    img.save(saved_image_path, format='JPEG', quality=95)\n","                    print(f\"  Input image saved as JPEG to: {saved_image_path}\")\n","                    saved_image_path_str = str(saved_image_path) # Store the full path as string\n","\n","                except Exception as img_save_error:\n","                    print(f\"  ERROR saving image as JPEG: {img_save_error}\")\n","                    saved_image_filename = None # Reset if saving failed\n","                    saved_image_path_str = None\n","\n","            # Prepare JSON for saving (remove base64, add image path)\n","            json_to_save = json.loads(json.dumps(final_json)) # Deep copy\n","            if json_to_save.get(\"user_inputs\",{}).get(\"image_reference\"):\n","                 # Remove base64 regardless of save success\n","                 if \"image_content_base64\" in json_to_save[\"user_inputs\"][\"image_reference\"]:\n","                      del json_to_save[\"user_inputs\"][\"image_reference\"][\"image_content_base64\"]\n","                 # Add path if image was saved successfully\n","                 # Store the relative path (just filename) within the output dir\n","                 json_to_save[\"user_inputs\"][\"image_reference\"][\"saved_image_path\"] = saved_image_filename\n","\n","\n","            # Save JSON\n","            json_filename = f\"{base_filename}.json\"\n","            json_filepath = output_dir / json_filename\n","            try:\n","                with open(json_filepath, 'w') as f:\n","                    json.dump(json_to_save, f, indent=2)\n","                print(f\"  Final JSON saved to: {json_filepath}\")\n","            except Exception as json_save_error:\n","                 print(f\"  ERROR saving JSON: {json_save_error}\")\n","\n","\n","            print(\"\\nProcessing complete.\")\n","            print(f\"--- Run FINISHED: {time.strftime('%Y-%m-%d %H:%M:%S')} ---\")\n","\n","\n","        except Exception as e:\n","            print(f\"\\n--- UNEXPECTED ERROR during processing ---\")\n","            print(f\"Error: {e}\")\n","            print(traceback.format_exc())\n","            if final_json: # Print the last known state of JSON if an error occurred later\n","                 print(\"\\n--- Last known JSON state before error ---\")\n","                 # Display without base64\n","                 final_json_display = json.loads(json.dumps(final_json)) # Deep copy\n","                 if final_json_display.get(\"user_inputs\",{}).get(\"image_reference\"):\n","                      if \"image_content_base64\" in final_json_display[\"user_inputs\"][\"image_reference\"]:\n","                           del final_json_display[\"user_inputs\"][\"image_reference\"][\"image_content_base64\"]\n","                 print(json.dumps(final_json_display, indent=2))\n","            print(f\"--- Run ENDED (Error): {time.strftime('%Y-%m-%d %H:%M:%S')} ---\")"]},{"cell_type":"code","source":["# @title Step 8: Run Processing Pipeline\n","# --- Instructions ---\n","# 1. Ensure you have selected the desired mode and filled in the inputs in Step 2.\n","# 2. Ensure the LLM Setup (Step 3) has been run and configured correctly if using LLM calls.\n","# 3. Run THIS cell to execute the pipeline processing steps.\n","\n","# --- Execution Code ---\n","run_pipeline_processing()\n","# Display the output area AFTER the processing function runs\n","clear_output()\n","display(output_area)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cafced0bed784dabb67aa49bda00e890","00b8c87131304e9d990c92d55c450e11"]},"id":"e3ZDRRYo-pRt","executionInfo":{"status":"ok","timestamp":1746184339289,"user_tz":-480,"elapsed":9227,"user":{"displayName":"Wei Bing Chuah","userId":"12139668370354715299"}},"outputId":"67135eb6-f3e2-4a23-87d7-3b17297080dc"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cafced0bed784dabb67aa49bda00e890"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRHpJkD3j8GY"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"034b7790a56746b7862a1072c523f442":{"model_module":"@jupyter-widgets/controls","model_name":"RadioButtonsModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"RadioButtonsModel","_options_labels":["Custom Mode","Task-Specific Mode"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"RadioButtonsView","description":"Select Mode:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_4d3111f9ab494b85892f7057797d7142","style":"IPY_MODEL_6daf70531edd4b25bb689f83c86caef7"}},"4d3111f9ab494b85892f7057797d7142":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6daf70531edd4b25bb689f83c86caef7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0872cd666ab149578bd18267820d1dcd":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_62e4a8790b0440f2b4961095be59d3be"],"layout":"IPY_MODEL_2541d82c8c064b6d804925da97cce2a1"}},"62e4a8790b0440f2b4961095be59d3be":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_bee1a206f4a7488f85cb0f25eba7fea1","IPY_MODEL_973c2c7bc34a41a2a6289fe2e16dcaa3","IPY_MODEL_8e5f7f65b9894c719a423807cd9b41b4","IPY_MODEL_127e21a762bc4432a05c94b7fa8c63d3","IPY_MODEL_4616e58cf6654595b4e63a189e2b2f45"],"layout":"IPY_MODEL_6e85b5f2e5da41c492a5dbfac576ae05"}},"2541d82c8c064b6d804925da97cce2a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bee1a206f4a7488f85cb0f25eba7fea1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5362e248c9b84fd980c1b4695b4c1543","placeholder":"​","style":"IPY_MODEL_3928405d15584354933b35f478068909","value":"<h3>Custom Mode Inputs:</h3>"}},"973c2c7bc34a41a2a6289fe2e16dcaa3":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Select Platform...","Instagram Post (1:1 Square)","Instagram Story/Reel (9:16 Vertical)","Facebook Post (Mixed)","Pinterest Pin (2:3 Vertical)","Xiaohongshu (Red Note) (3:4 Vertical)"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"*Platform Target:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_e5978779b80a41868886f56ed1af4f20","style":"IPY_MODEL_804bf02898ad441f94cfb065466fe6ce"}},"8e5f7f65b9894c719a423807cd9b41b4":{"model_module":"@jupyter-widgets/controls","model_name":"TextareaModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextareaModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextareaView","continuous_update":true,"description":"Prompt:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_c181a82dffb54b1e8f79ee8f3ba9a7b6","placeholder":"Enter your text prompt here (describe style, composition, setting, etc.)...","rows":null,"style":"IPY_MODEL_a90a796f014a4d2ea744772e14447b28","value":""}},"127e21a762bc4432a05c94b7fa8c63d3":{"model_module":"@jupyter-widgets/controls","model_name":"FileUploadModel","model_module_version":"1.5.0","state":{"_counter":0,"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FileUploadModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"FileUploadView","accept":"image/*","button_style":"","data":[],"description":"Upload Image Ref:","description_tooltip":null,"disabled":false,"error":"","icon":"upload","layout":"IPY_MODEL_f1de97be7ee44c35998d61abd8a3757f","metadata":[],"multiple":false,"style":"IPY_MODEL_200b485ed0ad40bba72a1f89fc262497"}},"4616e58cf6654595b4e63a189e2b2f45":{"model_module":"@jupyter-widgets/controls","model_name":"TextareaModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextareaModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextareaView","continuous_update":true,"description":"Image Instruction:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_3c723712a2bc4fed9dcebb4aa31e2922","placeholder":"(Optional) Provide brief instructions for the uploaded image (e.g., \"Use the burger as the main subject\", \"Describe the style and setting\", \"Extract the text\"). If empty, only the main subject will be identified.","rows":null,"style":"IPY_MODEL_218adfe7412d4cfb835b7da0b0ec0a94","value":""}},"6e85b5f2e5da41c492a5dbfac576ae05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5362e248c9b84fd980c1b4695b4c1543":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3928405d15584354933b35f478068909":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5978779b80a41868886f56ed1af4f20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"804bf02898ad441f94cfb065466fe6ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"c181a82dffb54b1e8f79ee8f3ba9a7b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"100px","justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"95%"}},"a90a796f014a4d2ea744772e14447b28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1de97be7ee44c35998d61abd8a3757f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"200b485ed0ad40bba72a1f89fc262497":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"3c723712a2bc4fed9dcebb4aa31e2922":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"60px","justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"95%"}},"218adfe7412d4cfb835b7da0b0ec0a94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cafced0bed784dabb67aa49bda00e890":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_00b8c87131304e9d990c92d55c450e11","msg_id":"","outputs":[{"output_type":"stream","name":"stdout","text":["Processing request... (Run started at 2025-05-02 09:47:36)\n","--- Step 1: Gathering Inputs ---\n","  Inputs gathered (excluding image content).\n","  Image 'Roti-Canai-6501-2.jpeg' processed.\n","\n","--- Step 2: Client-Side Input Validation ---\n","Status: Client-Side Validation: Inputs seem valid for the selected mode.\n","\n","--- Step 3: Generating Initial JSON ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": null,\n","    \"image_analysis_result\": null,\n","    \"suggested_marketing_strategies\": null,\n","    \"llm_call_usage\": {}\n","  }\n","}\n","\n","--- Step 4: Server-Side JSON Validation ---\n","Status: Server-Side Validation: JSON structure seems valid.\n","\n","--- Step 5: Image Evaluation ---\n","(Attempting VLM call via OpenRouter/Instructor for image 'Roti-Canai-6501-2.jpeg'...)\n","  Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["  Token Usage (Image Eval): {'completion_tokens': 13, 'prompt_tokens': 2696, 'total_tokens': 2709, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","  Successfully received and validated Pydantic response from VLM.\n","Status: Image 'Roti-Canai-6501-2.jpeg' (image/jpeg, 85617 bytes): Analysis complete (via VLM/Instructor).\n","\n","--- Step 6: Marketing Strategy Generation ---\n","Generating 5 marketing strategy suggestions...\n","  Stage 1: Starting Niche Identification...\n","    (Attempting LLM call for 3 Niche Identifications...)\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Niche ID): {'completion_tokens': 26, 'prompt_tokens': 270, 'total_tokens': 296, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Status: Niches identified via LLM: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Street Food']\n","  Using Niches: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Street Food'] for strategy generation.\n","  Stage 2: Starting Goal Combination Generation...\n","    (Attempting LLM call for Goal Combinations...)\n","    Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Goal Combos): {'completion_tokens': 233, 'prompt_tokens': 762, 'total_tokens': 995, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Successfully received and validated 5 marketing strategies from LLM.\n","  Stage 2: Goal combinations generated successfully (via LLM/Instructor).\n","Status: Marketing strategies generated (Niches identified via LLM: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Street Food']; Goal combinations generated successfully (via LLM/Instructor))\n","\n","--- Final JSON Output (after all processing) ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": true,\n","    \"image_analysis_result\": {\n","      \"main_subject\": \"Roti Canai with Curry Sauce\",\n","      \"secondary_elements\": null,\n","      \"setting_environment\": null,\n","      \"style_mood\": null,\n","      \"extracted_text\": null,\n","      \"suggested_keywords\": null\n","    },\n","    \"suggested_marketing_strategies\": [\n","      {\n","        \"target_audience\": \"Food enthusiasts interested in authentic Malaysian and Indian flavors\",\n","        \"target_niche\": \"Ethnic Cuisine (Malaysian/Indian)\",\n","        \"target_objective\": \"Increase awareness of traditional Roti Canai dishes to drive engagement\",\n","        \"target_voice\": \"Warm, inviting, and culturally rich\"\n","      },\n","      {\n","        \"target_audience\": \"Young adults and families looking for casual dining experiences\",\n","        \"target_niche\": \"Casual Dining\",\n","        \"target_objective\": \"Boost foot traffic to casual dining outlets serving Roti Canai\",\n","        \"target_voice\": \"Friendly, approachable, and relatable\"\n","      },\n","      {\n","        \"target_audience\": \"Urban foodies who follow street food trends and crave quick bites\",\n","        \"target_niche\": \"Street Food\",\n","        \"target_objective\": \"Drive online orders and social media shares of street-style Roti Canai\",\n","        \"target_voice\": \"Energetic, trendy, and vibrant\"\n","      },\n","      {\n","        \"target_audience\": \"Health-conscious consumers seeking authentic yet wholesome ethnic cuisine\",\n","        \"target_niche\": \"Ethnic Cuisine (Malaysian/Indian)\",\n","        \"target_objective\": \"Highlight the quality and authenticity of Malaysian/Indian Roti Canai to build brand trust\",\n","        \"target_voice\": \"Authentic, informative, and trustworthy\"\n","      },\n","      {\n","        \"target_audience\": \"Tourists and explorers interested in experiencing local street food culture\",\n","        \"target_niche\": \"Casual Dining\",\n","        \"target_objective\": \"Encourage visits to street food vendors featuring Roti Canai through visually appealing posts\",\n","        \"target_voice\": \"Exciting, adventurous, and descriptive\"\n","      }\n","    ],\n","    \"llm_call_usage\": {\n","      \"image_eval\": {\n","        \"completion_tokens\": 13,\n","        \"prompt_tokens\": 2696,\n","        \"total_tokens\": 2709,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      },\n","      \"strategy_niche_id\": {\n","        \"completion_tokens\": 26,\n","        \"prompt_tokens\": 270,\n","        \"total_tokens\": 296,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      },\n","      \"strategy_goal_gen\": {\n","        \"completion_tokens\": 233,\n","        \"prompt_tokens\": 762,\n","        \"total_tokens\": 995,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      }\n","    }\n","  }\n","}\n","\n","Processing complete.\n","--- Run FINISHED: 2025-05-02 09:47:44 ---\n"]},{"output_type":"stream","name":"stdout","text":["Processing request... (Run started at 2025-05-02 10:19:51)\n","--- Step 1: Gathering Inputs ---\n","  Inputs gathered (excluding image content).\n","  Image 'Roti-Canai-6501-2.jpeg' processed.\n","\n","--- Step 2: Client-Side Input Validation ---\n","Status: Client-Side Validation: Inputs seem valid for the selected mode.\n","\n","--- Step 3: Generating Initial JSON ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": null,\n","    \"image_analysis_result\": null,\n","    \"suggested_marketing_strategies\": null,\n","    \"llm_call_usage\": {}\n","  }\n","}\n","\n","--- Step 4: Server-Side JSON Validation ---\n","Status: Server-Side Validation: JSON structure seems valid.\n","\n","--- Step 5: Image Evaluation ---\n","(Attempting VLM call via OpenRouter/Instructor for image 'Roti-Canai-6501-2.jpeg'...)\n","  Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["  Token Usage (Image Eval): {'completion_tokens': 13, 'prompt_tokens': 2696, 'total_tokens': 2709, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","  Successfully received and validated Pydantic response from VLM.\n","Status: Image 'Roti-Canai-6501-2.jpeg' (image/jpeg, 85617 bytes): Analysis complete (via VLM/Instructor).\n","\n","--- Step 6: Marketing Strategy Generation ---\n","Generating 5 marketing strategy suggestions...\n","  Stage 1: Starting Niche Identification...\n","    (Attempting LLM call for 4 Niche Identifications...)\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Niche ID): {'completion_tokens': 31, 'prompt_tokens': 280, 'total_tokens': 311, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Status: Niches identified via LLM: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Street Food', 'Breakfast/Brunch']\n","  Using Niches: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Street Food', 'Breakfast/Brunch'] for strategy generation.\n","  Stage 2: Starting Goal Combination Generation...\n","    (Attempting LLM call for Goal Combinations...)\n","    Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Goal Combos): {'completion_tokens': 219, 'prompt_tokens': 800, 'total_tokens': 1019, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Successfully received and validated 5 marketing strategies from LLM.\n","  Stage 2: Goal combinations generated successfully (via LLM/Instructor).\n","Status: Marketing strategies generated (Niches identified via LLM: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Street Food', 'Breakfast/Brunch']; Goal combinations generated successfully (via LLM/Instructor))\n","\n","--- Final JSON Output (after all processing) ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": true,\n","    \"image_analysis_result\": {\n","      \"main_subject\": \"Roti Canai with Curry Sauce\",\n","      \"secondary_elements\": null,\n","      \"setting_environment\": null,\n","      \"style_mood\": null,\n","      \"extracted_text\": null,\n","      \"suggested_keywords\": null\n","    },\n","    \"suggested_marketing_strategies\": [\n","      {\n","        \"target_audience\": \"Food enthusiasts interested in authentic Malaysian and Indian flavors\",\n","        \"target_niche\": \"Ethnic Cuisine (Malaysian/Indian)\",\n","        \"target_objective\": \"Increase brand awareness and engagement for ethnic cuisine offerings\",\n","        \"target_voice\": \"Warm, inviting, and culturally rich\"\n","      },\n","      {\n","        \"target_audience\": \"Young professionals seeking casual dining experiences with flavorful dishes\",\n","        \"target_niche\": \"Casual Dining\",\n","        \"target_objective\": \"Drive foot traffic to casual dining locations featuring unique menu items\",\n","        \"target_voice\": \"Friendly, approachable, and modern\"\n","      },\n","      {\n","        \"target_audience\": \"Urban foodies who enjoy discovering popular street food delicacies\",\n","        \"target_niche\": \"Street Food\",\n","        \"target_objective\": \"Boost social media shares and interaction for street food specials\",\n","        \"target_voice\": \"Energetic, vibrant, and trendy\"\n","      },\n","      {\n","        \"target_audience\": \"Breakfast and brunch lovers looking for hearty and flavorful morning options\",\n","        \"target_niche\": \"Breakfast/Brunch\",\n","        \"target_objective\": \"Promote new breakfast menu items to increase morning sales\",\n","        \"target_voice\": \"Bright, cheerful, and appetizing\"\n","      },\n","      {\n","        \"target_audience\": \"Culinary adventurers interested in exploring diverse ethnic breakfast dishes\",\n","        \"target_niche\": \"Ethnic Cuisine (Malaysian/Indian)\",\n","        \"target_objective\": \"Educate and attract customers to try traditional roti canai with curry sauce\",\n","        \"target_voice\": \"Informative, authentic, and passionate\"\n","      }\n","    ],\n","    \"llm_call_usage\": {\n","      \"image_eval\": {\n","        \"completion_tokens\": 13,\n","        \"prompt_tokens\": 2696,\n","        \"total_tokens\": 2709,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      },\n","      \"strategy_gen_combined\": {\n","        \"completion_tokens\": 219,\n","        \"prompt_tokens\": 800,\n","        \"total_tokens\": 1019,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      }\n","    }\n","  }\n","}\n","\n","Processing complete.\n","--- Run FINISHED: 2025-05-02 10:19:58 ---\n"]},{"output_type":"stream","name":"stdout","text":["Processing request... (Run started at 20250502_103232)\n","--- Step 1: Gathering Inputs ---\n","  Inputs gathered (excluding image content).\n","  Image 'Roti-Canai-6501-2.jpeg' processed.\n","\n","--- Step 2: Client-Side Input Validation ---\n","Status: Client-Side Validation: Inputs seem valid for the selected mode.\n","\n","--- Step 3: Generating Initial JSON ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": null,\n","    \"image_analysis_result\": null,\n","    \"suggested_marketing_strategies\": null,\n","    \"llm_call_usage\": {}\n","  }\n","}\n","\n","--- Step 4: Server-Side JSON Validation ---\n","Status: Server-Side Validation: JSON structure seems valid.\n","\n","--- Step 5: Image Evaluation ---\n","(Attempting VLM call via OpenRouter/Instructor for image 'Roti-Canai-6501-2.jpeg'...)\n","  Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["  Token Usage (Image Eval): {'completion_tokens': 13, 'prompt_tokens': 2696, 'total_tokens': 2709, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","  Successfully received and validated Pydantic response from VLM.\n","Status: Image 'Roti-Canai-6501-2.jpeg' (image/jpeg, 85617 bytes): Analysis complete (via VLM/Instructor).\n","\n","--- Step 6: Marketing Strategy Generation ---\n","Generating 5 marketing strategy suggestions...\n","  Stage 1: Starting Niche Identification...\n","    (Attempting LLM call for 5 Niche Identifications...)\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Niche ID): {'completion_tokens': 36, 'prompt_tokens': 280, 'total_tokens': 316, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Status: Niches identified via LLM: ['Ethnic Cuisine (Malay/Indian)', 'Casual Dining', 'Street Food', 'Takeaway/Delivery Focused', 'Food Photography and Styling']\n","  Using Niches: ['Ethnic Cuisine (Malay/Indian)', 'Casual Dining', 'Street Food', 'Takeaway/Delivery Focused', 'Food Photography and Styling'] for strategy generation.\n","  Stage 2: Starting Goal Combination Generation...\n","    (Attempting LLM call for Goal Combinations...)\n","    Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Goal Combos): {'completion_tokens': 248, 'prompt_tokens': 806, 'total_tokens': 1054, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Successfully received and validated 5 marketing strategies from LLM.\n","  Stage 2: Goal combinations generated successfully (via LLM/Instructor).\n","Status: Marketing strategies generated (Niches identified via LLM: ['Ethnic Cuisine (Malay/Indian)', 'Casual Dining', 'Street Food', 'Takeaway/Delivery Focused', 'Food Photography and Styling']; Goal combinations generated successfully (via LLM/Instructor))\n","\n","--- Final JSON Output (Before File Save) ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": true,\n","    \"image_analysis_result\": {\n","      \"main_subject\": \"Roti Canai with Curry Sauce\",\n","      \"secondary_elements\": null,\n","      \"setting_environment\": null,\n","      \"style_mood\": null,\n","      \"extracted_text\": null,\n","      \"suggested_keywords\": null\n","    },\n","    \"suggested_marketing_strategies\": [\n","      {\n","        \"target_audience\": \"Food enthusiasts interested in authentic Malay and Indian flavors\",\n","        \"target_niche\": \"Ethnic Cuisine (Malay/Indian)\",\n","        \"target_objective\": \"Highlight the traditional appeal and authenticity of Roti Canai to increase cultural appreciation\",\n","        \"target_voice\": \"Warm, inviting, and culturally rich\"\n","      },\n","      {\n","        \"target_audience\": \"Young adults and families seeking casual dining experiences\",\n","        \"target_niche\": \"Casual Dining\",\n","        \"target_objective\": \"Encourage visits to casual dining spots by showcasing Roti Canai as a comforting and shareable dish\",\n","        \"target_voice\": \"Friendly, relaxed, and approachable\"\n","      },\n","      {\n","        \"target_audience\": \"Urban foodies and night market visitors who enjoy street food\",\n","        \"target_niche\": \"Street Food\",\n","        \"target_objective\": \"Boost engagement by promoting Roti Canai as a must-try street food snack with vibrant visuals\",\n","        \"target_voice\": \"Energetic, lively, and spontaneous\"\n","      },\n","      {\n","        \"target_audience\": \"Busy professionals and students who prefer convenient takeaway or delivery options\",\n","        \"target_niche\": \"Takeaway/Delivery Focused\",\n","        \"target_objective\": \"Drive online orders by emphasizing the convenience and deliciousness of Roti Canai with curry sauce\",\n","        \"target_voice\": \"Efficient, clear, and appetizing\"\n","      },\n","      {\n","        \"target_audience\": \"Food bloggers, photographers, and styling enthusiasts\",\n","        \"target_niche\": \"Food Photography and Styling\",\n","        \"target_objective\": \"Showcase high-quality food photography techniques using Roti Canai to inspire and educate\",\n","        \"target_voice\": \"Artistic, detailed, and professional\"\n","      }\n","    ],\n","    \"llm_call_usage\": {\n","      \"image_eval\": {\n","        \"completion_tokens\": 13,\n","        \"prompt_tokens\": 2696,\n","        \"total_tokens\": 2709,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      },\n","      \"strategy_gen_combined\": {\n","        \"completion_tokens\": 248,\n","        \"prompt_tokens\": 806,\n","        \"total_tokens\": 1054,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      }\n","    }\n","  }\n","}\n","\n","--- Step 7: Saving Output Files ---\n","  Input image saved to: pipeline_outputs/Roti-Canai-6501-2_20250502_103232.jpg\n","  Final JSON saved to: pipeline_outputs/output_20250502_103232.json\n","\n","Processing complete.\n","--- Run FINISHED: 2025-05-02 10:32:42 ---\n"]},{"output_type":"stream","name":"stdout","text":["Processing request... (Run started at 20250502_104514)\n","--- Step 1: Gathering Inputs ---\n","  Inputs gathered (excluding image content).\n","  Image 'Roti-Canai-6501-2.jpeg' processed.\n","\n","--- Step 2: Client-Side Input Validation ---\n","Status: Client-Side Validation: Inputs seem valid for the selected mode.\n","\n","--- Step 3: Generating Initial JSON ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": null,\n","    \"image_analysis_result\": null,\n","    \"suggested_marketing_strategies\": null,\n","    \"llm_call_usage\": {}\n","  }\n","}\n","\n","--- Step 4: Server-Side JSON Validation ---\n","Status: Server-Side Validation: JSON structure seems valid.\n","\n","--- Step 5: Image Evaluation ---\n","(Attempting VLM call via OpenRouter/Instructor for image 'Roti-Canai-6501-2.jpeg'...)\n","  Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["  Token Usage (Image Eval): {'completion_tokens': 13, 'prompt_tokens': 2696, 'total_tokens': 2709, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","  Successfully received and validated Pydantic response from VLM.\n","Status: Image 'Roti-Canai-6501-2.jpeg' (image/jpeg, 85617 bytes): Analysis complete (via VLM/Instructor).\n","\n","--- Step 6: Marketing Strategy Generation ---\n","Generating 5 marketing strategy suggestions...\n","  Stage 1: Starting Niche Identification...\n","    (Attempting LLM call for 5 Niche Identifications...)\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Niche ID): {'completion_tokens': 37, 'prompt_tokens': 280, 'total_tokens': 317, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Status: Niches identified via LLM: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Street Food', 'Food Photography Services', 'Takeaway/Delivery Focused']\n","  Using Niches: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Street Food', 'Food Photography Services', 'Takeaway/Delivery Focused'] for strategy generation.\n","  Stage 2: Starting Goal Combination Generation...\n","    (Attempting LLM call for Goal Combinations...)\n","    Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Goal Combos): {'completion_tokens': 231, 'prompt_tokens': 807, 'total_tokens': 1038, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Successfully received and validated 5 marketing strategies from LLM.\n","  Stage 2: Goal combinations generated successfully (via LLM/Instructor).\n","Status: Marketing strategies generated (Niches identified via LLM: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Street Food', 'Food Photography Services', 'Takeaway/Delivery Focused']; Goal combinations generated successfully (via LLM/Instructor))\n","\n","--- Final JSON Output (Before File Save) ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": true,\n","    \"image_analysis_result\": {\n","      \"main_subject\": \"Roti Canai with Curry Sauce\",\n","      \"secondary_elements\": null,\n","      \"setting_environment\": null,\n","      \"style_mood\": null,\n","      \"extracted_text\": null,\n","      \"suggested_keywords\": null\n","    },\n","    \"suggested_marketing_strategies\": [\n","      {\n","        \"target_audience\": \"Food enthusiasts interested in authentic Malaysian and Indian flavors\",\n","        \"target_niche\": \"Ethnic Cuisine (Malaysian/Indian)\",\n","        \"target_objective\": \"Increase awareness and engagement for ethnic Malaysian/Indian cuisine\",\n","        \"target_voice\": \"Warm, inviting, and culturally rich storytelling tone\"\n","      },\n","      {\n","        \"target_audience\": \"Young adults and families seeking casual dining experiences\",\n","        \"target_niche\": \"Casual Dining\",\n","        \"target_objective\": \"Drive foot traffic to casual dining venues serving roti canai\",\n","        \"target_voice\": \"Friendly, approachable, and conversational tone\"\n","      },\n","      {\n","        \"target_audience\": \"Urban foodies and tourists looking for popular street food treats\",\n","        \"target_niche\": \"Street Food\",\n","        \"target_objective\": \"Boost social media shares and local buzz around street food offerings\",\n","        \"target_voice\": \"Energetic, vibrant, and trendy voice with a sense of adventure\"\n","      },\n","      {\n","        \"target_audience\": \"Restaurants and cafes in need of professional food photography\",\n","        \"target_niche\": \"Food Photography Services\",\n","        \"target_objective\": \"Showcase the quality and appeal of food photography services specializing in ethnic dishes\",\n","        \"target_voice\": \"Professional, polished, and visually descriptive tone\"\n","      },\n","      {\n","        \"target_audience\": \"Busy professionals and families ordering takeaway or delivery\",\n","        \"target_niche\": \"Takeaway/Delivery Focused\",\n","        \"target_objective\": \"Increase online orders and promote convenience of takeaway/delivery options\",\n","        \"target_voice\": \"Clear, direct, and reassuring with a focus on convenience and taste\"\n","      }\n","    ],\n","    \"llm_call_usage\": {\n","      \"image_eval\": {\n","        \"completion_tokens\": 13,\n","        \"prompt_tokens\": 2696,\n","        \"total_tokens\": 2709,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      },\n","      \"strategy_gen_combined\": {\n","        \"completion_tokens\": 231,\n","        \"prompt_tokens\": 807,\n","        \"total_tokens\": 1038,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      }\n","    }\n","  }\n","}\n","\n","--- Step 7: Saving Output Files ---\n","  Input image saved as JPEG to: pipeline_outputs/Roti-Canai-6501-2_20250502_104514.jpeg\n","  Final JSON saved to: pipeline_outputs/output_20250502_104514.json\n","\n","Processing complete.\n","--- Run FINISHED: 2025-05-02 10:45:22 ---\n"]},{"output_type":"stream","name":"stdout","text":["Processing request... (Run started at 20250502_111209)\n","--- Step 1: Gathering Inputs ---\n","  Inputs gathered (excluding image content).\n","  Image 'Roti-Canai-6501-2.jpeg' processed.\n","\n","--- Step 2: Client-Side Input Validation ---\n","Status: Client-Side Validation: Inputs seem valid for the selected mode.\n","\n","--- Step 3: Generating Initial JSON ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": null,\n","    \"image_analysis_result\": null,\n","    \"suggested_marketing_strategies\": null,\n","    \"llm_call_usage\": {}\n","  }\n","}\n","\n","--- Step 4: Server-Side JSON Validation ---\n","Status: Server-Side Validation: JSON structure seems valid.\n","\n","--- Step 5: Image Evaluation ---\n","(Attempting VLM call via OpenRouter/Instructor for image 'Roti-Canai-6501-2.jpeg'...)\n","  Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["  Token Usage (Image Eval): {'completion_tokens': 13, 'prompt_tokens': 2696, 'total_tokens': 2709, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","  Successfully received and validated Pydantic response from VLM.\n","Status: Image 'Roti-Canai-6501-2.jpeg' (image/jpeg, 85617 bytes): Analysis complete (via VLM/Instructor).\n","\n","--- Step 6: Marketing Strategy Generation ---\n","Generating 5 marketing strategy suggestions...\n","  Stage 1: Starting Niche Identification...\n","    (Attempting LLM call for 3 Niche Identifications...)\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Niche ID): {'completion_tokens': 28, 'prompt_tokens': 280, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Status: Niches identified via LLM: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Food Photography and Styling']\n","  Using Niches: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Food Photography and Styling'] for strategy generation.\n","  Stage 2: Starting Goal Combination Generation...\n","    (Attempting LLM call for Goal Combinations...)\n","    Sending request to model: openai/gpt-4.1-mini\n"]},{"output_type":"stream","name":"stdout","text":["    Token Usage (Goal Combos): {'completion_tokens': 259, 'prompt_tokens': 796, 'total_tokens': 1055, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n","    Successfully received and validated 5 marketing strategies from LLM.\n","  Stage 2: Goal combinations generated successfully (via LLM/Instructor).\n","Status: Marketing strategies generated (Niches identified via LLM: ['Ethnic Cuisine (Malaysian/Indian)', 'Casual Dining', 'Food Photography and Styling']; Goal combinations generated successfully (via LLM/Instructor))\n","\n","--- Final JSON Output (Before File Save) ---\n","{\n","  \"request_details\": {\n","    \"mode\": \"task-specific_mode\",\n","    \"task_type\": \"1. Product Photography\",\n","    \"target_platform\": {\n","      \"name\": \"Instagram Post (1:1 Square)\",\n","      \"resolution\": {\n","        \"width\": 1080,\n","        \"height\": 1080,\n","        \"aspect_ratio\": \"1:1\"\n","      }\n","    }\n","  },\n","  \"user_inputs\": {\n","    \"prompt\": null,\n","    \"image_reference\": {\n","      \"filename\": \"Roti-Canai-6501-2.jpeg\",\n","      \"content_type\": \"image/jpeg\",\n","      \"size_bytes\": 85617,\n","      \"instruction\": null\n","    },\n","    \"branding_elements\": null,\n","    \"task_description\": null,\n","    \"marketing_goals\": null\n","  },\n","  \"processing_context\": {\n","    \"initial_json_valid\": true,\n","    \"image_analysis_result\": {\n","      \"main_subject\": \"Roti Canai with Curry Dip\",\n","      \"secondary_elements\": null,\n","      \"setting_environment\": null,\n","      \"style_mood\": null,\n","      \"extracted_text\": null,\n","      \"suggested_keywords\": null\n","    },\n","    \"suggested_marketing_strategies\": [\n","      {\n","        \"target_audience\": \"Food enthusiasts and adventurous eaters interested in Malaysian and Indian ethnic cuisines\",\n","        \"target_niche\": \"Ethnic Cuisine (Malaysian/Indian)\",\n","        \"target_objective\": \"Increase awareness and appreciation of authentic Roti Canai through engaging visuals\",\n","        \"target_voice\": \"Warm, inviting, and culturally rich\"\n","      },\n","      {\n","        \"target_audience\": \"Young professionals and families seeking casual dining experiences with flavorful, comforting dishes\",\n","        \"target_niche\": \"Casual Dining\",\n","        \"target_objective\": \"Drive foot traffic to casual dining outlets serving Roti Canai by showcasing its delicious appeal\",\n","        \"target_voice\": \"Friendly, approachable, and appetizing\"\n","      },\n","      {\n","        \"target_audience\": \"Social media users and foodies who follow food photography and styling trends\",\n","        \"target_niche\": \"Food Photography and Styling\",\n","        \"target_objective\": \"Boost engagement and followers by highlighting artistic and mouth-watering images of Roti Canai\",\n","        \"target_voice\": \"Creative, trendy, and visually captivating\"\n","      },\n","      {\n","        \"target_audience\": \"Health-conscious consumers curious about ethnic dishes with balanced ingredients\",\n","        \"target_niche\": \"Ethnic Cuisine (Malaysian/Indian)\",\n","        \"target_objective\": \"Educate audience on the nutritional value and unique flavors of Roti Canai paired with curry dip\",\n","        \"target_voice\": \"Informative, sincere, and wholesome\"\n","      },\n","      {\n","        \"target_audience\": \"Culinary students and amateur chefs interested in ethnic cooking techniques and presentation\",\n","        \"target_niche\": \"Casual Dining\",\n","        \"target_objective\": \"Inspire and teach the art of making and styling Roti Canai for digital and print media\",\n","        \"target_voice\": \"Educational, detailed, and passionate\"\n","      }\n","    ],\n","    \"llm_call_usage\": {\n","      \"image_eval\": {\n","        \"completion_tokens\": 13,\n","        \"prompt_tokens\": 2696,\n","        \"total_tokens\": 2709,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      },\n","      \"strategy_gen_combined\": {\n","        \"completion_tokens\": 259,\n","        \"prompt_tokens\": 796,\n","        \"total_tokens\": 1055,\n","        \"completion_tokens_details\": {\n","          \"accepted_prediction_tokens\": null,\n","          \"audio_tokens\": 0,\n","          \"reasoning_tokens\": 0,\n","          \"rejected_prediction_tokens\": null\n","        },\n","        \"prompt_tokens_details\": {\n","          \"audio_tokens\": 0,\n","          \"cached_tokens\": 0\n","        }\n","      }\n","    }\n","  }\n","}\n","\n","--- Step 7: Saving Output Files ---\n","  Output directory: /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/pipeline_upstream_outputs\n","  Input image saved as JPEG to: /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/pipeline_upstream_outputs/Roti-Canai-6501-2_20250502_111209.jpeg\n","  Final JSON saved to: /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/pipeline_upstream_outputs/output_20250502_111209.json\n","\n","Processing complete.\n","--- Run FINISHED: 2025-05-02 11:12:19 ---\n"]}]}},"00b8c87131304e9d990c92d55c450e11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}